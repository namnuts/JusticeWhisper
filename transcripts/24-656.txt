We will hear argument this morning in case 24656 tick tock versus Garland and the consolidated case. Mr. Francisco. Mr. Chief justice, and may it please the Court. Under the act, one of America's most popular speech platforms will shut down in nine days. That shouldn't happen for three reasons. First, TikTok Incorporated is a US company speaking in the United States. The act requires it to go dark unless ByteDance executes a qualified divestiture. Whether you call that a ban or a divestiture, one thing is clear. It's a burden on TikTok speech. So the First Amendment applies. Second, the act is content based from beginning to end. It applies only to social media platforms that have user generated content, except for business product and travel reviews. Within that content based universe, it singles out a single speaker for uniquely harsh treatment. And it does so because the government fears that China could in the Future indirectly pressure TikTok to disseminate foreign misinformation and propaganda. Finally, the act can't satisfy any standard of scrutiny. The government has no valid interest in preventing foreign propaganda and its fallback that it seeks merely to prevent covertness makes no sense since that could be addressed with a risk disclosure. The government's real target rather is the speech itself. Its fear that Americans, even if fully informed, could be persuaded by Chinese misinformation. That, however, is a decision that the First Amendment leaves to the people, given that the government's data security rationale cannot independently sustain the actual it is also grossly under inclusive and ignores the most obvious, less restrictive alternative, simply banning TikTok Incorporated from sharing any sensitive user data with anyone. In short, this act should not stand at a minimum. You should preliminarily enjoin it, which will allow you to carefully consider this momentous issue and for the reasons explained by the President Elect, potentially moot the case. I welcome your questions. Exactly what is TikTok's speech here? TikTok, your honor, uses an algorithm that in its view reflects the best mix of content. What the act does is it says TikTok cannot do that unless ByteDance executes a qualified divestiture. That's a direct burden on TikTok speech, much less of a burden than the one that this court struck down in the Simon and Schuster case where all the author had to do was take a certain amount of proceeds and put it into an escrow account for a short period of time to satisfy a civil judgment. So why does a restriction on bytedance, which is not a citizen, is not located in the US a restriction on TikTok because what the law says to TikTok is that TikTok you cannot use the algorithm that you prefer to use unless ByteDance executes a qualified divestiture. So the law therefore falls directly on TikTok itself. It imposes a burden on TikTok speech. Again, a much less, much more significant burden than the one that was struck down in Simon and Schuster. You're converting the restriction on ByteDance's ownership of the algorithm and the company into a restriction on TikTok speech. So why can't we simply look at it as a restriction on ByteDance? Because I think the burden falls directly on TikTok. And I can use a hypothetical that helps illustrate the point. Suppose that China used its leverage over Jeff Bezos international empire, including his Chinese businesses, to force the Washington Post to write whatever China wanted on the front page of the Post. Surely the government couldn't come in and say, jeff Bezos, you need to either sell the Washington Post or shut it down. That wouldn't just violate Mr. Bezos First Amendment rights, that would also violate the Washington Post First Amendment rights, because they are ultimately the one that's suffering the burden under that law because they have to go dark and close up their books. Counsel, you began by saying this is a US Company operating in the United States. Yes, you, Honor. But the ultimate company that controls it, ByteDance, was found by Congress, and I'll quote this to be subject to Chinese laws that require it to assist or cooperate with the Chinese government's intelligence work quotes and to ensure that the Chinese government has the power to access and control private data that the company holds. So are we supposed to ignore the fact that the ultimate parent is in fact subject to doing intelligence work for the Chinese government? Well, your honor, I don't think you are supposed to ignore that at all. But I also don't think that it changes the analysis for a couple of reasons. Look, tick tock. Well, just hold a second. Well, as I said, you began by saying this is a US Company operating in the United States. And it seems to me that you're ignoring the major concern here of Congress, which was Chinese manipulation of the content and acquisition and harvesting of. Of the content. Sure. And I'll start by saying that TikTok Incorporated is a United States subsidiary operating in the United States with its own set of free speech rights. Do you dispute the fact that ByteDance has ultimate control of TikTok in its corporate organization? Yes, your Honor, I do dispute that. But I also don't think that it matters because even if China could exercise overwhelming power against TikTok versus ByteDance. I don't think it would change the analysis. And I can take that Washington Post hypothetical and ratchet it up a little bit to help illustrate the point. Let's suppose that the Chinese government had actually taken the Bezos children hostage and it was using that leverage in order to force Bezos and the Washington Post to publish whatever they wanted on the front page of the Post. So China effectively has total control. I still don't think that Congress could come in and tell Bezos either sell the Post or. Or shut it down because that would violate Bezos rights and the Washington Post rights. Maybe what they could do is come in and say, you need to disclose the fact that you're under this amount of coercion so that the people who are looking at the paper understand it and can make their own assessment. But I think the First Amendment rights of both Bezos and the Post would be directly implicated. Notwithstanding that, China in that scenario has effectively total control over what gets printed in the Washington Post. Counsel, let me break this down. I understand your argument that there is a First Amendment right that the US Company has. I'll go that far with you. Okay, I'll take. Because we're affecting their ability to talk in some. In whatever way they choose. The Washington Post could choose, without any influence or threat against the children of Mr. Bezos to promote Chinese policy. And our First Amendment would permit them to do that if they chose it independently, correct? Yes. Now the question becomes. So it's not. That's just a given that they have a First Amendment right. The next question is, assuming they do, what's the level of scrutiny we apply? Isn't that what the issue here? That is certainly one of the issues, your honor. All right, so if we get to that side of the issue, that TikTok USA has some sort of First Amendment right, taking your example, if the government said, no speaker is free to speak under a criminal compulsion by someone else because of extortion, because of kidnapping. We are doing this because it is the only way to ensure the safety of people, that they are not going to be kidnapped or threatened, their lives threatened. You don't think that the government has a compelling state interest in saying if there is a threat, a physical, criminal threat against someone to do some activity that the government couldn't say? I'm not questioning whatever the content is of that activity. I'm simply saying we in our governmental powers have a right to say, you can't do that. You can't speak sure, you, Honor. So, to take your question in pieces, I do think that they would have a compelling interest in that scenario to do something. But what I don't think is that they could simply target speakers in speech. Take, for example, generally applicable laws like the treaty. So you think in that situation that it, that the only thing the government could do is tell the Washington Post, disclose to the public that you are saying this because you are being forced to, so that that's the only remedy the government could undertake? No, you, Honor, but I want to make sure I understand the hypothetical. The compelling interest is in preventing this kind of compulsion, coercion, and ultimately harm to children. And I think that the government has a lot, lot of different ways they can address that through speech neutral laws. And I was going to point to things like the Trading with the Enemy act or Russia sanctions. You can broadly say an attack problem. Very effective. Well, be that we're still having people kidnapped, we're still having coercion. And be that as it may, you can say to Americans, you cannot collaborate with our enemies at all. And if you do that, you're going to be severely punished for doing that. We can move on to the effectiveness of the remedy. But the point is, I believe that even if your First Amendment rights are impinged and there is some protection, the question is at what level of scrutiny. Yes, you, Honor. Whether that the action is content neutral or not, I agree that that is the way that the analysis proceeds here. We believe that the level of scrutiny should be strict scrutiny. What is the relevance of the history? Chief Judge Srinivasan, in his opinion in the D.C. circuit, emphasized that there is a long tradition of preventing foreign ownership or control of media in the United States, going back radio, television and what have you. I would think no matter the level of scrutiny, that history has to be important. And I want to get your response to it. I don't actually think it's important in this context because that history all arises in the context of bandwidth scarcity. And in that context, you have the government that's in the position of doling out a limited number of licenses. And when you have to dole out a limited number of licenses, you by definition have to pick winners and losers. And when you have to do that, you get a certain amount of discretion. I think that's the whole basis of those cases. You can't really take those cases. Keep going. You can't really take those cases and extend them to an area where there is no scarcity, like the World Wide Web. Because once you do that. There's really no limiting principle. There's no reason why that wouldn't also apply to really popular books or magazines or newspapers or chains of newspapers. The bandwidth scarcity, I think, is really what justifies the greater discretion that the government gets in that area. Mr. Francisco, let me see if I can break this down. Suppose that TikTok were outright owned by the People's Republic of China. Would you make the same argument? I wouldn't be making the same argument, your honor. Why not? Because there you would have to confront a very different question. Whether a foreign government that was speaking in the United States has first amendment rights. And I don't know that the court has ever addressed that, but here we've got a U.S. no, I understand that. I just want to see where you draw the line. So it's true. The court has never held that a foreign government has free speech rights. And if we were to hold that, I would think it would be because speech by a foreign government, particularly one with enormous resources, is not protected. Allowing that does not serve the underlying interests of the first amendment, which are, among other things, fostering democratic self government and furthering the search for truth. So let's assume that that's. We start with that. All right. What if TikTok were then not owned by the foreign government, but it was undisputed that TikTok was totally controlled by the foreign government, could not do one thing without the approval of the foreign government? That's different. I do think that it is different, your honor. For example, you know, I've given the hypothetical that I've given, but there are a lot of companies in this country that have foreign owners, not just companies like Politico, which is German owned, or Al Jazeera, which is partly owned by the government, Qatar. I understand that, but what would be the reason for drawing that line? Sure, because if there's a good reason for saying that a foreign government, particularly an adversary, does not have free speech rights in the United States, why would it all change if it was simply hidden under some kind of contrived corporate structure? Because it is a US Speaker. I'll give you another example. AMC movie theaters used to be owned by a Chinese company. Under this theory, Congress could order AMC movie theaters to censor any movies that Congress doesn't like or promote any movies that Congress wanted. And I think the. The reason is that here, where it's conceded you actually have a bona fide US Company, it is not simply a Chinese cutout. That is the Chinese government speaking itself. All right, let's say that United States company say this is not a complete answer to your first amendment argument, but would you be willing to concede that this is a very important factor that should be taken into account in deciding whether there's the first amendment violation? Well, your honor, I think that it does help supply a compelling governmental interest, but I still think you have to march through the strict scrutiny analysis and analyze their interests. I do not think that they have a compelling government mental interest in the manipulation of content. I think that is in the teeth of the first amendment. And if you look at the government's brief and the rest of the record in this case, that's really what it's focused on. The their complaint is the fear that the content could be critical of the United States government or could undermine our democracy. Yes, your honor. Mr. Francisco, I just wanted to follow up on that line of question with just some fact questions because it seems to me there are a couple of things that the parties still dispute about facts in this court, which is a little unusual. The government says that TikTok US has no authority or ability to alter the algorithm or recommendation engine, but must simply follow ByteDance's directives. You disagree with that in your reply brief. Somebody has to be right and somebody has to be wrong about that. What's, what's the fact? What does the record show? Well, your honor, we are here on a record and there is nothing in the record that says that TikTok like any other subsidiary, doesn't have its own independent making authority. If you look at their record sites, what they point point to is the ordinary types of control that a parent company has over a subsidiary company. But it doesn't change the fact. What is the fact? Are you prepared to make a representation? Yes, your honor. The fact is that TikTok Incorporated as a US company does have a choice over the algorithm. Now, it would be an incredibly bad business decision for them to abandon this algorithm, and they very doubtful would ever do it. But they have that authority. What they clearly have the authority to do is shut down the platform in the face of Chinese pressure. That's actually what they agreed to do in the national security agreement. I think that underscores why TikTok Incorporated as a U.S. company does have its own set of First Amendment rights. Okay, and then another fact question before the D.C. circuit. You. You argued that the Chinese government has made clear in public statements that would not permit a forced divestment of the recommendation engine. Does that mean that some key component of the recommendation engine is under Chinese control? No, your Honor, what it means, and this might warrant a little more explanation, what it means is that there are lots of parts of the source code that are embodied in intellectual property that are owned by the Chinese government. And they would restrict, like the United States restricts, the sale of those types of things to foreign government. It doesn't alter the fact that this is being operated in the United States by TikTok Incorporated. So I got it. Okay? I got it. And then you represent the divestiture is not feasible within the act's time frame. I'm sorry for these fact questions. I just want to understand what's before us. Would it be feasible in any time frame? I take the government doesn't dispute that it's infeasible in the 270 days provided by law. Would it be. Your Honor, I think at least as we understand how they've interpreted the qualified divestiture provision, it would be exceedingly difficult under any timeframe for two principal reasons. The first is that there's a global team of engineers that are, some in China, some in Europe, some in the United States that maintain and update the original source code. And as we understand their interpretation, a qualified divestiture would prohibit any kind of coordination with that global team of engineers. The other reason is because as we understand how they're interpreting it, a qualified divestiture would divorce the US Platform from the global content. So, for example, there are videos created in the United States. There are videos created in Ireland. In order to get global content, we need access to the Irish videos. They need access to the US Videos. We understand that couldn't happen. Okay, so you think it's probably not feasible in any timeline? Well, you, Honor, I think it'd be extraordinarily difficult. Okay, last. Last fact question, then. I'll yield the floor here. The government admits that it has no evidence that TikTok has engaged in covert content manipulation in this country, but says that ByteDance has responded to PRC demands to censor content outside of China in other countries. Again, you deny that in your reply brief. Somebody has to be right about that. Well, your honor, the problem there is everything that follows what you just read is redacted. And so I don't know what it says. What the record shows is two things. The record shows first, what you just said. They haven't done anything here in the United States with respect to TikTok Incorporated. And second, the record also shows through our transparency reports that we haven't removed or restricted content on the TikTok platform in other parts of the world. And TikTok doesn't operate in China. It operates in other parts of the world. We haven't removed or restricted content at the request of China. That's what we put out in our regular transparency. Restricted, though, doesn't necessarily cover covert content manipulation, though. Right. Well, your honor, I'm limiting my response to what's in the record. It's very difficult for me to respond to things that I where I don't know what the accused. I have other questions about. About the secret evidence of this case, but we'll get to that later. Thanks for that. Mr. Francisco, can I ask you a question about the relevant speech here? So it strikes me that this is a little different than your Bezos example, because there it's clearly content discrimination because we're talking about the ability to post particular articles versus other articles. Am I right that the algorithm is the speech here? Yes, your honor. Well, I would say it's. The algorithm is a lot of things the algorithm has built within it. It's basically how we predict what our customers want to see. The editorial discretion. Yeah, the editorial discretion. It also has built within it the moderation elements. All of this kind of comes together when the source code is translated into executable code in the United States. In the United States, that executable code is then subject to vetting, review, moderation through content moderation algorithm, and that. So it ultimately lands on the TikTok platform. But what we're talking about as a net choice is the editorial discretion that underlies the algorithm. And I just want to be clear. A lot of your examples talk about, including the Bezos one. The right of an American citizen to repeat what a foreign entity says or say. You know, I'm hitching my wagon to China. I want to say everything China does here, the concern is about the COVID content manipulation piece of the algorithm. That is something that bytedance wants to speak. Right? Well, your honor, I think that ultimately it's TikTok's choice whether to put it on the platform. And you don't want that. Are you. Is your client disclaiming? We absolutely resist any kind of content manipulation by China at all. But what I do want to focus in on is what their asserted interests here. They do talk about covertness, but it can't possibly be that all they're concerned about is mere covertness. If all you were concerned about was the covertness untethered from the underlying content. That's something that could be easily addressed through a risk disclosure that goes to scrutiny. The level of the application. I'm trying to. I mean, let's say that I agree with you. The first amendment is implicated, and I'm trying to figure out what level of scrutiny applies. And I'm trying to figure out what content, if any, discrimination is going on here. You know, there's a disproportionate burden. Let's say that I agree with you about that. No one is preventing you. I mean, you're seeking access to a particular source code, engineering the recommendation feature. It's the technology that you want. You're not trying to repeat, as in the Bezos example, if we take the speech that the government's concerned about to be the COVID content manipulation rationale, you're not seeking to utter that speech. That's correct, your honor. What we are seeking to do is use an algorithm that displays the combination of content that we prefer our users to see on the platform. And the government doesn't care about that. I mean, the government is fine with you doing that. You can invent it yourself. It doesn't even care what content that displays cat videos or whatever. Yeah, but I think that the way that the analysis has to unfold is first you ask, is this law burdening our speech? I think we agree that the law is burdening our speech. Then you have to look at whether the law itself is somehow content based. Not just what their motivations are, but whether the law is content based. And here, the trigger for this law, the one thing that gets it going, is if you operate a social media platform that has user generated content, unless that content takes the form of a product, travel or business review, then within that universe of content, it says, there's one speaker we're particularly concerned about and we're going to hammer home on that one speaker. And then just to make the rubble bounce, they come in and tell us that one of the reasons they're targeting that speaker is because they're worried about the future content on that platform, that it could in the future somehow be critical of the United States or undermine democracy to pull examples from the government's brief. So I think there's no way to get around the fact that this is a content based speech restriction. And you do have to go directly to what their interests are now, their principal interests. Could I. I think I'm a little bit surprised by one of the answers that you gave to Justice Barrett. I had understood that TikTok's essential complaint here is that they wouldn't be able to use the algorithm that ByteDance has invented and that they want to use the algorithm that ByteDance has invented. 100%. And if I was unclear on that, you, Honor, I apologize. That is a problem. Okay, Because I think what justice Barrett was saying to you is like, what's the problem here? Because ByteDance is a foreign company. Or maybe this isn't what justice Barrett says, It's just what I say. Bytedance is a foreign company, and you started off with justice Alito saying, well, we would be making a different argument. And of course that's true. I mean, I would think that alliance for open society makes it pretty clear that you have to be making a different argument with respect to a foreign state or a foreign company. So let's say that they don't have First Amendment rights. The only First Amendment rights lie in TikTok, which does have First Amendment rights. And I guess my question is, how are those first amendment rights really being implicated here? This, this statute says the foreign company has to divest. Whether or not that's feasible, however long it takes, TikTok still has the ability to use whatever algorithm at once, doesn't it? No, your honor. And their rights are implicated at a most basic level. In 10 days, TikTok wants to speak. In 10 days, because this law was passed, TikTok cannot speak unless ByteDance executes a qualified divestiture. That's not just ByteDance's choice. That is a. That is a condition. It definitely has effects on TikTok if ByteDance acts in the way that you are assuming it will act. So this is not to say that the First Amendment isn't involved, because TikTok is going to suffer some pretty severe incidental effects. But they are incidental, aren't they? Because the statute only says to this foreign company, divest or else, and leaves TikTok with the ability to do what every other actor in the United States can do, which is go find the best available algorithm. I very much disagree that the effects are incidental, because the way that this law works is it is only triggered if somebody is engaging in speech based on their content. User generated content, except for business product and travel reviews. It then singles out a single speaker. And you have the concession for the government that one of the reasons they singled out that speaker idea of just like, you know, I think what you're basically saying is that all speaker based restrictions generate strict scrutiny. I'm not sure that we've ever said anything like that. You know, let's put aside the face. Your argument that this is facially content based. It seems to me that your stronger argument or at least the one that most interested me was this argument of, look, if the government is doing something specifically for the purpose of changing the content that people see, that has to be subject to strict scrutiny. But I don't see that as affecting TikTok as opposed to. As affecting ByteDance. Well, no, no, I very much do see it as affecting TikTok because they choose this algorithm because it reflects the mix of content. The government's fear is that China could come in and pressure TikTok, TikTok through byteness to TikTok to alter that mix of content to make it too pro Chinese or too anti American. That is very much directly a content based charge straight at TikTok. The other point I would like, I hear you, that it might very well have that effect. I guess what I'm suggesting is that the law is only targeted at this foreign corporation which doesn't have First Amendment rights. Whatever effect it has, it has. You know, maybe bytedance will figure out a way to like put this on open Source and then TikTok will be able to use the algorithm. So, your honor, if I could take that on directly, because to the. I think TikTok has First Amendment rights. To the extent ByteDance is speaking in the United States, it, I believe, has First Amendment rights. If you conclude that neither has First Amendment rights, then surely the creators have First Amendment rights. But if you take a step back, what their position is, is that none of these entities, this is the universe of entities affected by this law, none of these entities have the authority to assert First Amendment rights. Which means that the government really could come in and say, I'm going to shut down TikTok because it's too pro Republican or too pro Democrat or won't disseminate the speech I want. And that would get no First Amendment scrutiny by anybody. That cannot possibly be the case. Yet that is the effect of their position. The last point I'd like to emphasize though, is this law, like the Playboy case, like the Hobby Lobby case, has built within it a less restrictive alternative, which is the general provision by definition designed to protect against the very harm the government is identifying. Suppose New York State passes an asbestos abatement law. They say these types of buildings have to abate asbestos. In addition, New York Times, you have to abate asbestos in your building. And they say there are two reasons for this. One, we want to abate asbestos. Two, we hate the New York Times editorial page. Surely at the very least what you're going to say is you can't target the New York Times directly. What you can do is throw them into the general process. Thank you. We think that's the minimum that should be done here. Thank you. Council, we've been talking about connection between the regulation of TikTok and the burden on expressive conduct. And your basic position is that interfering with the ownership of TikTok constitutes a direct regulation of the expressive conduct of other people. What is your best example in our precedent of a situation where we've. A regulation of corporate structure or something else has been treated as a direct regulation of expressive conduct? The regulation of a corporate structure as a. Your honor, I don't have a case at my fingertips. I can. Well, I don't have one at my fingertips or any other rebuttal, but I, but I think it's quite clear, though that if you're saying to a company, you have to stop talking unless somebody else does something and that's imposed by the force of law, it directly affects that company's speech. Well, that's, it's. Again, I don't know if it's directly affecting the company's speech or the speech of third parties. And I'm not sure what, you know, where your emphasis is, but again, I'm not sure there's another case where we've said that regulating a company has. Should be others expression should be treated as direct imposition on their speech in terms of the standard of review, for example, when it's based on derivative regulation of corporate structure of somebody else. Well, your honor, I think that it's. I would concede that this is a pretty unprecedented case. I'm not aware of any time in American history where the Congress has tried to shut down a major speech platform. But I think that if a law imposes a direct regulation on a third party that in turn results in shutting down somebody else's speech. And they do it for content based, viewpoint based reasons. And in particular on this record, because the speaker that is ultimately being shut down, they don't like the speech of that particular platform. That's a real problem. But it may be a real problem or may not. But I just am wondering if there's any precedent where we have that same connection and that it affects the standard of review. For example, you would treat it as a direct restriction on expression even the only thing the law does is say in this case, somebody other than the Chinese government has to own speech. So we don't have any direct precedent along the lines that you're citing. But we do have precedents. We have cases like Acara and what Acara says is if the law is totally speech neutral, then that's one thing. We have cases like O'Brien which say if the law doesn't care about speech but happens to draw in speech, that's another thing. Both of those cases make clear, however, is that when the law is concerned with the content of the speech, when the justification is based on the content of the speech, that's cases like Read two, then you do trigger strict scrutiny. So then I think your argument comes down to is this direct concern with speech or is it concerned with the potential for Chinese interference with the level of interference indirectly. In other words, they're not coming back. The Chinese government. TikTok doesn't care what the people are saying on TikTok. That's not the concern. The concern is that they are regulating a particular channel of communication. And I just wonder if there's any precedent for that type of thing. They're not saying we're going to restrict this content and that content, but not this. They're just saying we're going to be in a position where we can control what happens, whether it's based on expression, whether it's based on anything else. So, your honor, I disagree. And I think if you take a step back and look at this record, I think it is quite clear that it is focused on both current and potential Future Content. On TikTok, TikTok Incorporated here, you don't have just an act that is based on speakers and speech. It's triggered by speech. It's focused on a Single Speech or TikTok incorporate Speaker. TikTok Incorporated Incorporated. Justice Thomas, Justice Alito what if Congress, if there were nothing in this act about content moderation or covert manipulation, what if it was just about preventing what Congress viewed as an enormously powerful popular application from gathering an arsenal of. Of information about American citizens? And they said this is the worst offender and we're going to require divestiture by this offender. Would there be a First Amendment problem there? And if you think there would be, what would the level of scrutiny be? Yes, there would be a First Amendment problem if you had a law like this that was only focused on speakers. Those who use user generated content other than product traveler business. Well, Congress, Congress concludes that this particular entity is the worst. This is the worst offender, and it happens to be an entity that is involved with speech. If all you had. So I want to make sure I understand the hypothetical. The only provision you have is one that says this company has to shut down because of data security. Right. I would have A different set of arguments. I think it would still implicate the First Amendment, particularly where you have strong evidence that they were being targeted, in part at least because of their speakers and speech. Suppose Congress passed the law that you passed. Well, but you're changing that. You're changing the hypothetical by injecting congressional concern about the. Okay, well, I'll put that to the side. So what would your argument be? It would be an equal protection argument. No, no, I'd still be saying. I'd still be saying that Acara itself makes clear that where a law disproportionately burdens just a speaker, we have to subject that to scrutinies, to suss it out, to suss out whether the asserted interest is the actual interest there. The asserted interest is in data security. I think I would have a couple of arguments. Under whatever form of scrutiny you wanted to apply, whether it is strict scrutiny or intermediate scrutiny. In that context, I would say first that that law is dramatically under inclusive because it categorically exempts E commerce apps that this record shows have comparable ties to China. You said, I don't want to prolong too much. You say this is not like Arkara. I think primarily because you say that divestiture requires the new company to cease using the algorithm. Right. No, I think it's not like Acara. For a much more fundamental sense, Acara involved a totally speech neutral law. It didn't go after speakers at all. If you had a law in Acara that said we're going to prohibit prostitution in bookstores only then I think that a car would have come out differently. There would have at least been, you know, some kind of intermediate scrutiny, potentially strict. Well, you're. That's the law that I think is your hypothetical. Away from the hypothetical that I think for the purpose of narrowing in on what your, on what your argument is. My. I understood you to say that it. This. That would not be a, a solution to the problem because one of Congress's motivations was. Was the content was based on the content of TikTok. Am I wrong in that? Did I read your argument incorrectly? Well, I think that I want to make sure I understand what you're saying. I certainly think that because one of the motivations was content, that is an enormously important fact. I was trying to answer your hypothetical where we were trying to take that out of the mix. And the reason why, why Acara is different is because Acara didn't just simply say no prostitution in bookstores. That's what your hypothetical effectively says. It says no data security problems in speakers or in this particular speaker, and I think that that would trigger, at the very least intermediate scrutiny. All right. Thank you. Thank you, Justice Sotomayor. That goes to my question, which is, justice, the Chief justice asked you whether or not we've ever had a case where pure ownership was at issue and not speech, and I don't think we had one like that. You're right, but I don't think that your question, that the question gets to the essence of your argument. Is it. The essence of your argument is you're being asked to divest because of speech, Correct? Correct. All right. So if I get past that, if I go to Justice Alito's point, which is I don't think it's just about speech, it's about data control. If it's about data control and assume for the sake of argument that I believe intermediate scrutiny applies to the data control provision, then your arguments would be different, wouldn't they? They would be under inclusiveness. They would be other arguments, correct? Well, you, Honor, I think they'd be very similar because I think the nature of our arguments work just as well under intermediate and strict scrutiny. If I could unpack that a little bit. No, I'm not going to because we're going to run out of time because we're going to need to figure out what intermediate scrutiny means. But I'm not sure it means what you do, which is I don't think any of our cases have ever suggested that we have to use the least restricted means under intermediate scrutiny. In fact, our cases have said we have to use a reasonable means. And if I could respond to that point specifically, I completely agree it's not a least restrictive means alternative. Your Honor, but you do have to at least consider alternatives here. If the concern let's take the data security concern, which you put your finger on. I know you want to keep going on, but I can't let you because I can't monopolize the argument. Okay, but let me just get to the bottom of that. All right. You seem to suggest that Congress has to actually look at all of the alternatives and say, no, I don't think we have a case that says that. I am not saying that from the record it's clear that alternatives won't be adequate for whatever set of reasons. Isn't that enough? If the record were clear on that, that might be enough. Now let me go to the next question and the last if I could, you, Honor, just one sentence. If on the key less restrictive alternatives, they had actually considered them and said what you suggested, this would be a different case. But our point is that on the key, most obvious, less restrictive alternatives, a law, for example, that simply prohibits TikTok Incorporated from sharing any sensitive user data with ByteDance or anyone else. There's nothing in the record that suggests they even considered it, and that's why it would fail under even intermediate scrutiny. We have a different problem, which is that the record shows that there is no sharing that could happen. That wouldn't put the data at security. But we can go back to. That's incorrect, actually. No, because the NSA doesn't. I'm not talking about the NSA or even anything else. But putting that aside, one last question. Assuming that the COVID manipulation issue is one, I think that what remains is to the chief's question and justice Alito's questions, if the COVID manipulation is a concern, then the question becomes what kind of burden does it put on TikTok USA? And I think your point is that that requires strict scrutiny because it doesn't permit them to speak to the Chinese government through the algorithm and promote whatever speech it wants to promote through the algorithm. It doesn't permit them to speak to the American public through the algorithm. Right. And promote whatever type of speech they want to promote on the algorithm. And I also think that this covert manipulation is a little bit odd. They're not concerned just with covertness. If all you were concerned with. I'm going to ask she about the. That. How do you disentangle the two things? Thank you, your honor. Justice Kate, Justice Gorsuch, Justice Kavanaugh, just on the data collection interest, I think Congress and the president were concerned that China was accessing information about millions of Americans, tens of millions of Americans, including teenagers, people in their 20s, that they would use that information over time to develop spies, to turn people to blackmail people. People who a generation from now will be working in the FBI or the CIA or in the state department. Is that not a realistic assessment by congress and the president of the risks here? Well, your honor, I'm not disputing the risks. I'm disputing the means that they have chosen one way, the most direct way to address that. All of this user data sits on data servers in Virginia controlled by Oracle. I'm not talking about the national security agreement. What I'm talking about is a law that Simply says to TikTok Incorporated and its US employees, you cannot share that user data with anybody. You can't give it to ByteDance, you can't give it to China. You can't give it to Google, you can't give it to Amazon, you cannot give it to anybody under threat of massive penalties. They never even considered that most obvious alternative. And so whether you apply intermediate scrutiny or strict scrutiny, it's not a least restrictive means test, but you got to at least consider the most obvious alternative. So you acknowledge the risk that Congress and the President were concerned about. You're just saying the means they chose to address that risk were incorrect. So I have not permissible. I mean, I certainly acknowledge the risk, but I think there are lots of reasons, not just the one I just gave, but there are lots of reasons why that risk still can't justify the law when it sits alongside of the impermissible covert manipulation risk. I think it falls under Mount Healthy. It's no different if they came in and said, we passed this law one for data security. I understand that. But just on the data collection, that seems like a huge concern for the future of the country. And your honor, again, it is a concern. Two responses. First, it is a concern that can be addressed directly. The reason why there's no evidence in this record about whether that kind of direct prohibition on TikTok Incorporated from sharing sensitive user data with anybody, including ByteDance. The reason why the record is devoid of any evidence of that is because Congress never considered the other side of the balance. And that's the minimum that Congress has to do under the First Amendment. It's got to at least consider the consequences of shutting down a speech platform used by 170 million Americans against the benefits of an alternative. Like Simply saying to TikTok's employees, you're essentially going to get massive fines, potentially jail sentences, if you share any of that sensitive user data with anybody. Not TikTok, not Byte. I'm sorry, not ByteDance, not China, not anybody else else in the world. Yet there's nothing in this record that suggests they even considered that alternative. What happens after January 19th if you lose this case? Can you just spell that out? At least as I understand it, we go dark. Essentially, the platform shuts down. Unless there's a divestiture. Unless there's a divestiture. Unless President Trump exercises his authority to extend it by night. But he can't do that on January 19th. On January 19th, we still have President Biden. And on January 19th, as I understand it, we shut down. It is possible that come January 20th, 21st, 22nd, we might be in a different world again. That's one of the reasons why I think it makes perfect sense to issue a preliminary injunction here and simply buy everybody a little breathing space. This is an enormous amount. What do you mean by shut down, too? Can you just spell that out? So if you. One, the app is not available in the app stores, that's at a minimum. But in addition, what the act says is that all of the other types of service providers can't provide service either. Now, there's enormous consequences for violating that for the service providers. So essentially, you know, what they're going to say is that I think we're not going to be providing the services necessary to have you see it. So it's essentially going to stop operating. I think. I think that's the consequence of this law, which again is why a short reprieve here would make all the sense in the world. It's an enormously consequential decision, and I think all would benefit if it weren't necessary. Thank you, Justice Sparrett. So I just want to just kind of following up on Justice Kavanaugh's questions. Let's say I agree with you that some level of scrutiny applies, and I'm trying to figure out which level of scrutiny applies, and I'm trying to figure out if there's content discrimination. And let me ask you different question than I did before about the algorithm. I mean, you keep saying shut down. The law doesn't say TikTok has to shut down. It says ByteDance has to divest. If ByteDance divested TikTok, we wouldn't be here. Right. If ByteDance was willing to let you go and willing to let you take the source code with you, that would be fine. Right? We would not be here. Well, Your Honor, if ByteDance divested, then the law wouldn't fall on TikTok, but the law will. The law, not ByteDance. But that's because ByteDance's choice, right? I mean, well, this is like Justice Kagan's point. I mean, I'm trying to figure out how we account for the reality of third party choices and the. The choices of third parties that the whole reason for the law being passed in the first place. Yeah. Your honor, I still don't. I think that the way the analysis works is step one, is there a first amendment violation? Right. Step two, you get to the question that we're grappling with. What standard of scrutiny do you apply? Typically, what you do is you ask, is this law content based? Is it content based on its base? Is it content based in its decision? Here we know it's content based on its face because it says what it says. We know it's content based in its motivation because the government concedes its content based in its motivation. That's not quite what I'm asking. I mean, that's the dispute between you and the government. Is is it content based if it's about divestiture and not about telling TikTok what content it can display on the platform? And I think it has to be because that's, I think that that really goes to the first question. Does the burden fall on the speaker? If the burden falls on the speaker, that triggers the speaker's First Amendment rights. But the law is in fact content based, whether it comes in the form of a divestiture or something else. When the law specifically says it's content based, we're worried about the content on the platform. And when the government tells you that, one of our reasons, one of the things that we're worried about is TikTok, not ByteDance, but TikTok Incorporated and TikTok in the United States will, absent the divestiture, have a mix of content that we find objectionable. They will mix around their videos in a way that is too pro Chinese or too anti American. Okay, tock the platform. Let me just ask you one last question. Why is it impossible to divest in the 260, 70 days, even assuming that the Chinese government hadn't said you couldn't? Sure. And this is the exchange I was having with Justice Gorsuch. There are two basic reasons. The first is that the underlying source code, that's the source code that comes in here and then has to be converted. But that's what Justice Gorsuch said, just not ever. So it's not really that you can't do it within the timeframe. It's that you really couldn't ever divest because you never are going to get the source code. So. Well, let me unpack that a little bit. No, it's that we, with the underlying source code, it takes a team of engineers to update and maintain that. It would take us many years to reconstruct a brand new team of engineers to do that with respect to the source code, with respect to the sharing of content. That was the different reason. In theory, we could kind of send our salesmen around the world, go to Ireland, go to Finland, go to every country and say, look, you used to automatically get our content, but now you gotta separately sign up. Okay. For our platform. Last, last point. Let me make sure I understand what you're saying. It's not that you couldn't execute the disentanglement you could say we're independent. You just can't recreate TikTok in any kind of way. Well, I think that any new TikTok would be a fundamentally different platform with different content, which is yet another reason why I think this is a content based restriction that falls directly on TikTok incorporated itself in our platform. Justice Jackson. So I guess I'm back to some of the questions that Justice Barrett and Justice Kagan asked about the sort of threshold issue that you point out, which is is there a burden on the speaker? I'm trying to understand what the burden is that you are articulating and whether it really isn't about association and not speech. You say you have in your brief some cases that talk about American speakers being free to choose whether to affiliate with foreign organizations. And the colloquy you had with Justice Kagan made me think that what you're really complaining about is the inability to associate with ByteDance and its algorithm that it's not really about, you know, if TikTok came up with its own algorithm or bought an algorithm from some other company or devised it or whatever, this law would have nothing to do with them from your perspective. But the problem I think you're articulating, and this is, I'm seeking your clarification. Sure. The problem I think you're articulating is that you want to use ByteDance's algorithm and therefore associate with ByteDance, and Congress has prohibited that by requiring divestiture. So isn't this really a right of association case? I think it's, I think it's both, your honor. I do think that that is a component of it. We want to use the algorithm that we think reflects the best mix of content. That's the algorithm that reflects the best mix of content. What this law says is we can't do that unless ByteDance exercises a qualified divestiture. But I also think more directly what this law, law does is it says to TikTok Incorporated, if ByteDance doesn't exercise a qualified divestiture, you have to go mute, you cannot speak at all. No, I don't think it says that, though. I mean, if, if TikTok were to post divestiture or whatever, pre divestiture, come up with its own algorithm. Right. Then when the divestiture happened, it could still operate. It doesn't say TikTok. You can't theoretically correct, your honor, but I think that also underscore the content based nature of the restriction. No, but the fact, the fact that that's true suggests that you're wrong about the statute being read as saying TikTok, you have to go mute because TikTok can continue to operate on its own algorithm on its own terms as long as it's not associated with bytedance. So isn't this really just all about association? Your honor, I think it is partly about association, but I'm taking another shot at explaining why it's not just about association. Okay, well, let me just take you down the association path for a second, because if it is about the association of TikTok with bytedance, then don't we have cases that seem to undermine your view that congress can't do this? I mean, I thought we had cases about congress prohibiting association with terrorist organizations, prohibiting association with foreign adversaries. And so why doesn't this fall into that kind of group of our jurisdictions? Well, at least, as I understand all of those cases, they applied strict scrutiny. The material support statute most definitely applied and ultimately upheld the law. So, fine, but sure. And I think if we go down the strict scrutiny road here, I don't see that this law can possibly be satisfied under the interest that they assert here. But I do want to emphasize why this is also about TikTok speech. Even under your hypothetical word, theoretically, they can say something differently than they are saying today. That in and of itself is a direct restriction on TikTok speech. They can't engage in the speech they want to engage in. They have to engage in a different kind of speech, the speech they don't want to engage in. That is a direct burden on TikTok incorporated speech. All right, I think. Let me ask you a question about your colloquy with justice Kavanaugh. Did I understand you to concede that there is a compelling interest and that the problem is really tailoring? I mean, you said, I understand the risks. I don't hear you suggesting that the risks don't exist. So it sounds like we've gotten past, even if we're in strict scrutiny world. We've gotten past the compelling interest part of this. No, your honor, what I was saying is that all you had standing alone were the data security. That would be a different case here when you have the content manipulation sitting right alongside of the data security that taints the data security rationale. If congress came in and said, we're passing this law for two reasons. One, we really care about data security, and two, we hate the speech on TikTok, the data security wouldn't alone sustain that law under cases like Mount Pleasant. I understand, but why you're equating we don't want foreign adversaries to be able to manipulate the content on this platform. You're equating that with we hate the content. And I'm just trying to understand. Sure. Why. Because content manipulation is by definition a content based distinction. Look, everybody manipulates content. There are lots of people who think cnn, Fox News, the Wall Street Journal, the New York Times are manipulating their content. That is core protected speech. That's why they put so much weight on this mere covertness. Right. But that's that. But that analysis is just about content based versus content neutral. And therefore whether you apply strict scrutiny. I'm in the strict scrutiny world. Okay. I'm assuming that you're right that strict scrutiny applies. And now prong number one in that world is does the government have a compelling interest? And so I'm trying to understand why the government's argument that we have data manipulation concerns, which I understood you in colloquy with Justice Kavanaugh to say is a risk. And we are concerned based on what Justice Gorsuch says when he's looking at the facts, you know, that the government contends that there's this risk, real problem with this foreign adversary doing manipulation in other places. Are you saying those are not compelling government interests? I am 100% saying that content manipulation is not just not a compelling governmental interest, it is an impermissible governmental interest. You could not go to CNN or Fox News and say we're going to regulate you because you're manipulating the content in the way that we don't like that is per se impermissible. Can I just ask you one last thing? You say with respect to the tailoring issue, that disclosure you think is a possible, more narrowly tailored way of handling some of this. And I guess I'm just wondering whether disclosure under this court's case law and the law of other lower courts, courts, doesn't carry its own first amendment complications that don't we have. Wouldn't we have compelled speech problems if disclosure was required in this situation? Sure, your honor. Now look, I might think so because I think that the factual predicate is wrong, but they think the factual predicate is right. And if the factual predicate is right, then there are no first amendment problems at all under Zauder and the cases that you're suggesting. And that underscores the larger problem here. Not all disclosures are perfect. I'm not here to argue that they are. But you've always got to consider what the alternative is. And here the alternative is shutting down One of the largest speech platforms in America. The reason there's no evidence in this record as to disclosures is because Congress never even undertook that balancing in the first place. Thank you. The bare minimum that has to be done before we take an umbrella, unprecedented step of shutting down the voices of 170 million Americans. Thank you. Thank you, counsel. Mr. Fischer. Mr. Chief justice, and may it please the Court. Wholly apart from the company's legal interests here, the act directly restricts the rights, the First Amendment rights of American creators to participate and speak. And with a court a little less than a decade ago called the modern public square, and what you might say today is the most vibrant speech forum in the United States of America. And the act, therefore, is inescapably subject to strict scrutiny because of the First Amendment implications. And the act fails that test and indeed any level of scrutiny under this Court's case law, because the act and the reasons behind it defy our history and tradition as well as precedent. American creators have long and always enjoyed the right to speak in conjunction with foreign speakers or work with foreign publishers. Americans even have the right under the Lamont case to receive information from foreign speakers, indeed foreign governments. So that leaves the government with its implication and its use of the phrase national security in this context. But that just simply doesn't change the calculus. Throughout our history, we have faced ideological campaigns by force, foreign adversaries. Yet under the First Amendment, mere ideas do not constitute a national security threat. Restricting speech because it might sow doubt about our leaders or undermine democracy are kind of things our enemies do. It is not what we do in this country. And so we think the Court should reverse. And I would welcome the Court's questions. How exactly are the creator's speech being impeded? So two ways. Justice Thomas First, I just point you to the text of the statute, which directly regulates text, images, real time communications, videos. My clients, the creators, are the ones creating that speech and posting it to speak to other artists. But it doesn't say anything about creators or people who use the site. It's only concerned about the ownership and the concerns that data will be manipulated or there will be other national security problems with someone who's not a citizen of this country or a company that's not here. So there's two ways. I think the Sorrel case is where you look for the analysis of the First Amendment burden here. As I said, the text of the statute regulates our speech and then you point out ownership. And this was talked about a lot in the first part of the argument here. So let me be very clear. The American creators have a right to work with the publisher of their choice. So imagine somebody wanted to work on post speech on Twitter, now known as X, and Congress passed a law saying we don't like the current owner of X. The current owner of X has to sell that platform or else it has to shut down. People who post on that platform and who indeed some of them make a living commentating, engaging on current events, news, politics would have a First Amendment claim to work with X. Using that argument, you could have said that about the breakup of AT&T. You could say that about the foreign limitations of on foreign ownership of broadcast companies. Well, no, I think that you have to dig a little deeper than that, Justice Thomas. It's not mere foreign ownership and it's certainly the broadcast cases I'll get to in a moment. But it's foreign ownership because of a particular perspective. If you boil it down to an essence, the owner of a print media or online media publication is the essence of the viewpoint of that publication. The current owner of X, or the current owner of Fox News or the current owner of MSNBC has a particular perspective and working with that particular platform is shot through with the ownership from top to bottom. But why couldn't Congress prohibit Americans from associating with certain foreign organizations that have interests that are hostile to the United States? I mean, I thought that's what Holder vs. Humir Humanitarian law Project allowed. So I don't really understand what you mean. Right, so I'm glad you're bringing that up. Yes. So when it comes to this national security, you are right that Congress can prohibit Americans to use that case as an example from associating with terrorist organizations or other organizations that pose a clear and present danger to this country. This case, Justice Jackson, is fundamentally different. What the government tells you in its own brief that it is worried about here are the ideas that might be expressed on TikTok. We might undermine U.S. leadership. We might sow doubts about democracy. We might have pro China views. And so if you look to whether that is legitimate interest, my fundamental submission, this I think goes to the last colloquy you were having with Mr. Francisco is that is an impermissible government interest. And you look throughout our history and tradition and I think the place I would point you most directly would be the opinions of Justice Brandeis and Whitney and Justice Holmes and Abrams. I guess I don't understand how that's distinguishable from what's happening in Holder. So can you just say a little bit? It goes to the nature of the national security threat. So my position is the government just doesn't get to come in and say national security in the case is over, or you don't get to associate. You have to dig underneath what is the national security claim. And what Justice Holmes said in his Abrams dissent, and I know that was a dissent, these are hard issues, but that has been vindicated over time, is that it's not enough to say national security. You have to say, what is the real harm? Is it, you know, is it terrorism? Is it where are. Where our battleships are located? Justice Kavanaugh presented a number of potential risks right, with. With foreign adversaries using covert manipulation of the data platforms that are being used by youths today. That would then make it more likely that people would turn into spies and do terrible things to the United States. This is a hypothetical, but you know what I'm saying, I get it. So I think if I understood Justice Kavanaugh correctly, he was talking about the data security argument. So let me just pull these apart. You first have an argument, and the government itself separates these two arguments in its brief. The first argument, the one I'm focusing on initially, is the content manipulation argument. And that argument is that our national security is implicated if the content on TikTok is anti democracy, undermines trust in our leaders. They use various phrases like that in their brief. So my primary submission is that is an impermissible government interest that taints the entire act. Now, there's a secondary argument the government makes, and we say you don't even get to that because once you have an impermissible motive like that, the law is unconstitutional. But even if you could get to that. Justice Jackson, I do grant that data security and the way Justice Kavanaugh spelled it out is compelling. That is compelling. But that's not the question. You just don't ask in the air, you know, was Congress worried about data security or could it reasonably be worried about data security? You say, can this act, the act before you, be sustained on data security grounds? And our answer to that has to be no. Don't have to look any further than the divestiture provision itself, which says that the content recommendation algorithm cannot be used in the future. Well, that has nothing to do with data security. So the core feature of the divestiture provision is going at content manipulation, which I said is impermissible. You can't uphold that under data security grounds. And the rest of the act, when you look at the covered companies provision, Justice Jackson, if this were primarily a data security law, what you think you'd find is what kind of data is procured? How is it stored? Is it shared? Those are the things you think you'd find under covered companies, but you don't find that. What you find is are text images shared? Is content being shared between users? Is it being created and posted in a social media platform? So I don't dispute for one second that data security is a very important thing. And Congress in this very law, regulated data security in other ways with data brokers. That's perfectly permissible. But the question before you today was narrower. The question is, is this law before you sustainable? UN data security grounds? And that answer has to be no. Congress doesn't care about what's on TikTok. They don't care about the expression that's shown by the remedy. They're not saying TikTok has to stop. They're saying the Chinese have to stop controlling TikTok. So it's not any direct burden on the expression at all. Congress is fine with the expression. They're not fine with a foreign adversary as they've determined it is gathering all this information about the 170 million people who use TikTok. Well, again, Mr. G. Justice, if I may, let me separate the where you started, which was the content manipulation, and then go to the data security part of it. So. Well, the first part, I'm not talking about the content manipulation. I'm talking about the content harvesting. When you say content harvesting, do you mean people got all the information, whatever algorithms they want, that has access to the personal information or at least information that is not readily available about 170 million Americans, and whether they're going to use it in 10 or 15 years, when those people grow up and, you know, have different jobs in different places, or whether they're going to use it. Now that at least as I look at the Congressional record, is what Congress was concerned about. About. Well, I think. And they're not concerned about the fact that it is available. As I said, the remedy is just somebody else has to run TikTok. So they're not concerned about the content. They're concerned about what the foreign adversary is doing. So if I may, I think I still, to answer your question properly, I think I have to separate two things. One is the content recommendation algorithm, and that's what I was speaking about a moment ago. That has nothing to do with data security. That doesn't itself procure data. That just determines what videos people see on their feed on TikTok. As to that, I think the answer is inescapably that the government and Congress itself was worried about content. The government itself is here saying national security. So like a mix of cat videos or dance videos doesn't affect national security. No matter what happens, the only thing that can affect data security. I'm sorry, national security are the substance of those videos. And when the government's pressed in its briefing, it outright tells you that it says, what we're really worried about is sowing doubts about US Leaders, et cetera. So let me turn then to data security. Yes, there were various congresspersons, and in the record that we have in the D.C. circuit, there were conversation about the problem of data security. Here, as I said, I don't dispute that that is a valid governmental interest. So I think you addressed whether that alone can sustain the act in two steps. First, you would ask if you have an impermissible motive and a permissible one, can we sustain the act based on the impermissive, based simply on the permissible motive? And I think for the reasons Mr. Francisco said, and we lay out in our brief that alone, the answer is no. Under Hunter Underwood and other cases, even if you could get just to the data security question, again, you'd have to ask the question, would this law have been passed by Congress for data security reasons? Because you're as being asked to uphold a law based on that single governmental interest. And when you look through the provisions, like the content recommendation algorithm provision, like the covered company provisions, the answer is no. And if you're still in doubt on that, just go back to the under inclusiveness problem. What a Congress really worried about these very dramatic risks. Leave out an E commerce site like temu that has 70 million Americans using it and every bit that connects. Does Congress have to go all or nothing on that? It doesn't have to go all or nothing. If they isolate a particular problem, they might be getting to what you're talking about next. Who knows? But you're really sitting up there and saying, Congress would not pass the divestiture law if data security were the only interest. So I'm saying it would not have passed this divestiture law if data security were the only interest. It's very curious why you just single out TikTok alone and not other companies with tens of millions of people having their own data taken, you know, in the process of engaging with those websites and equally, if not more, available to Chinese control. So I'm not trying to say that Congress has to do everything at once. I'm trying to say that once you've concluded that content manipulation, for the reasons I've said as a matter of our history and tradition, has to be impermissible. Is there another site like this one that covers half the American population? I don't think just by way of sheer numbers, Justice Sotomayor, that the answer has to be no. But 70 million seems like a lot. 170 million is a lot. But put that aside and then go to the next question, which is how many of these sites have all of the data collected mechanisms that TikTok has? From what I understand from the briefs, not only is it getting your information, it's asking and most people give it permission to access your contact list, whether that contact list has permitted them to or not. So they can now have data about all of your contacts and anything you say about them. How many other sites gather information by keystrokes to be able to do voice and finger ID information if they choose? And there's a whole lot of data stuff that was discussed in the brief that I don't think any other website gathers. So wouldn't, wouldn't this be a unique site if I viewed the evidence that way? How would this be under inclusive? Justice Sotomayor? I don't think a lot of the suppositions you're making actually bear out. And as Justice Gorsuch was pointing out, one of the obviously the real challenges in this case is it comes to you without an ordinary trial record compiled and all the rest. So we have only limited amounts of information. But absolutely these other websites are taking much the same kind of information, if not more. And as to the, as to the contact list thing, I think you also that points out one other aspect of this that is voluntary decision by an American user to share that information, you know, in the Reilly case, but not informed. And even if that could be solved, but you don't think it's informed, that could be solved because for the United States the threat of using that information is what is at issue. It's not whether the user thinks it's okay, it's whether the US believes that it could put sites at issue. But let me ask you one last question and fundamental question. Assuming that content, that content neutral data collection concerns were Congress is one of Congress's provisions divests because of this. Why can't we separate that out from how we analyze the algorithm question and couldn't we sever the two provisions to say divestiture is right, but you can't force them not to discuss algorithm? Well, I think the reason why you can't do that, as Mr. Francisco explained, I thought I'd direct you to a case like Hunter against Underwood and just analogize it to this situation. If what you had is the government saying we are shutting down TikTok or requiring divestiture for two reasons. One, because we think it helps the Democratic Party too much, and number two, because we're concerned about data. I think that first interest would be a poison pill. That would be an impermissible. Or because we think it, you know, there's too much pro Catholic content on TikTok. I think there are some interests that are just so constitutionally verboten that I think that that just makes the act unconstitutional. And you can't go looking for other interests. You send it back to Congress. Look, if you want to pass a data security law free and clear of this impermissible interest, you go ahead and do it. Can I say one other thing, Justice Sotomayor? Just because I think it is also telling here that even if you didn't buy that poison pill argument, and you just asked whether Congress would have passed this law, something else that I think you might notice is even if all this act goes into effect and the law goes through, TikTok gets to keep all the data. So wouldn't a data security law require them to expunge that data or get rid of it or something? I mean, it's a very weird law if you're just looking at. Through a data security lens. And maybe Congress could do better. Mr. Fisher, often we require divestiture for any trust reasons. For example, and as I take it, your argument here, and we don't think of those as normally implicating the First Amendment interests of users or people who might speak or associate with editors. And the difference here is, as I understand it in your mind, that this law is motivated by a conflict content based interest. Is that. Is that a fair summary? I think that. And the only thing I would add to it is just the prior step, which it is. It is regulating the speech itself for content based reasons. Yeah, we don't do that in the antitrust area. Exactly. Say this law does. Exactly. And it does. On the content, covert content manipulation side. Do you think that's a compelling interest or not? Forget about the tailoring for a moment. No, my point is, is that preventing content manipulation, whether it's covert or not, is simply not impermissible. If what you mean by content manipulation are the kinds of interests the government is saying, like undermining trust in our leaders, you know, Whitney and Abrams. That's Whitney and Abrams. And like those cases. I got it. Yeah, I got it. So just a couple more. I'm sorry, I'll finish up real quick. And so that would take us to the tailoring question. And there you say disclosure and alerting Americans that there is covert content manipulation possibility, putting aside the data collection part of it, telling Americans that there is content, covert content manipulation going on in TikTok or at least it's possible. And the government says that's just simply not enough. And the D.C. circuit did too. And I wanted to give you a chance to respond. Right. So I think that's the only aspect of the governmental interest that could be permissible, the COVID part. And my answer, as you just said, is disclosure solves that problem. And you have a law, a long standing law which we haven't talked about yet today that gives you that example. Again, under history and tradition test, you look at not just precedent, but laws and traditions of our country. Look at the Foreign Agent Registration act passed, passed in the run up to World War II. And the concern was Americans would be controlled by foreign agents to speak and advocate certain causes. We didn't ban them. We did not ban them. All you did is require you Congress. All Congress did was require disclosure. Certainly wasn't. I wasn't around for that. On the secret evidence point, I'm concerned about the government's attempt to lodge secret evidence in this case without providing providing any mechanism for opposing counsel to review it. And I expressed that concern in Zibeta and I noted that there are mechanisms to read in council and that other countries, including our allies, often do that. I just wanted to give you a chance to give me your thoughts on that. Yes, Justice Gorsuch, we made all those arguments in the D.C. circuit. So there was a flurry of motion practice about whether or not the government could rely on classified evidence. Those motions were never resolved, but the D.C. circuit did. I think you probably noticed from the decision is say we're going to decide this case solely based on the public record. And my understanding is that's how it comes to this court. If the court were ever. It's interesting that Congress hasn't acted in this field. I mean we have in the FISA area, you know, lots of opportunity. They have regulated this area. And it does seem like an area that Congress might want to pay attention to given the increased appeals to secret evidence that the government has made in recent years. Last question for you. Could the new administration after January 20, Mr. Francisco suggested that it might be able to extend the deadline even though if you were to lose here by January 19th. Is that possible? As you read the law, I'm not sure it is. I'm not sure. Maybe that's a question for, for the Solicitor General, but. Oh, it certainly is. I thought maybe I'd give you a chance too. So, you know, as I understand the law, it's 270 days unless extended. And once that time runs, I'm not sure you're talking about an extension anymore. You know, there's expos facto law that kind of does this stuff. Thank you. Can I take you back, Mr. Fisher? Let's say I agree with you that if you're talking about content manipulation, that's an inherently content based rationale for acting. So if Congress had passed a law that says we hate the content manipulation that TikTok is doing, that's strict scrutiny land. And I don't know that the government can do that, however important and, you know, the interest. But that's not what Congress is doing here. And this is the same kinds of questions that I asked Mr. Francisco, because if, let's take it as a given that Congress actually can do whatever it wants once with respect to a wholly foreign corporation or a foreign government. And so Congress could act with the intent to interfere with the content manipulation that a foreign corporation is doing. And so now we're in this strange world where we're saying they can't act with respect to TikTok, they could act with respect to ByteDance. Why isn't this Congress acting with respect to ByteDance in the sense that all it's doing is saying ByteDance has to divest, and then TikTok can go about its business, use whatever algorithm it wants, use whatever content moderation policies it wants, just like everybody else does, choosing from everything that's available on the open market. So let me answer that question in two parts from the perspective of the creator, Americans who want to use this platform to speak to other Americans. So the first thing is what the act does, as you said, Justice Kagan, is prevent us from working with a application that is owned by ByteDance that uses this algorithm. Well, that's exactly what we want to do. That's our editor and publisher of choice that we think best disseminates our students. Yeah, but what I'm saying to you is if you just assume a world without TikTok, that where it's only ByteDance. And you were trying to, you were trying to say, well, we really want to work with, with ByteDance. And Congress was saying, we think ByteDance presents national security interests and they don't have First Amendment rights. They're just a foreign corporation. I think that in that case, the government. I mean, tell me if you think this is wrong. It just doesn't matter that you have creators who want to work with ByteDance because ByteDance is a foreign corporation with no First Amendment rights. Is that what you're contesting? So that is what I'm contesting. So you said two things, though, so I could be clear. There's two aspects. Do we have a First Amendment right to work with a foreign company or even a foreign country to publish our speech? And then there's a national security part that you put into that, which goes to the justification. Forget that. Forget that. Yes, let's do that. So if that is right, Justice Kagan, then American creators have no right to make documentaries with the BBC. They can't work with Al Jazeera. If Congress wants to prevent that, any number of other publications that are state owned, whole, wholly or partially, and even under Lamont. Remember where you're not even creating speech, you're just listening. You know, that was speech from China that the Court said you have a First Amendment right to receive it. Would I be right to say that your position is that because of the users who want to associate and want to partner with this foreign corporation, the foreign corporation ends up having, in your view, the exact same First Amendment rights as your users do. In other words, it's irrelevant that the foreign corporation doesn't have First Amendment rights. I don't think it's irrelevant because you could imagine a situation where no American distributor or speaker wants to work with that. But let me put it to you this way. The Communist Manifesto written by Karl Marx has no First Amendment standing on its own in America. But if a bookstore wants to sell that publication, I don't think Congress can prevent it from doing so. Well. Oh, sorry. Go ahead. No, I'm fine. No, no, no, I'm good. Okay. So I want to. But I want to press you a little bit on the distinction, because in Lamont, the prohibition worked directly on the American. Like, you have to specifically request this information that comes. This is working kind of as Justice Kagan's questions were pressing you. This is working on Bite Dance. It's not saying to your creators you can't post on ByteDance. That's indirectly going to happen if ByteDance chooses itself not to permit TikTok to walk away with the code. So does that matter, that distinction between Lamont and this case? No. For two reasons. One, under the Sorrel case, you look to not just the law itself, but its practical operation. And the practical operation is prevent us from working with ByteDance. So that's one. And you bring up Lamont, and Lamont's actually a very important case. I'm sure you all recognize here. It's important to look not just at the court's opinion, but look at the briefing in that case. The government itself never came in and argued there's no right to receive this information. That's the sort of greater argument. All the government argued was, of course, Americans have a right to receive this, but it's just not so much of a burden to require them to raise their hand to get it. So Archibald Cox, when he was the Solicitor General, said to the Court quite explicitly in the brief, we're not even going to make this argument because we think it's so contrary to history and tradition. All we're going to argue is the burden isn't enough. Now, what happened is the D.C. circuit kind of turned that upside down and said, oh, Lamont's just a case about the burden. Well, that's because that's the only argument the government was even willing to make in this court. There was no argument that Americans didn't have the right to hear that speech. What about. So I think this goes to Justice Gorsuch's questions about antitrust divestiture. Let's say that. Let's say that for antitrust reasons, or let's even say not for that. Let's say for suspect First Amendment reasons, Congress tells Jeff Bezos that he has to divest in the Washington Post. You know, he can no longer own the Post. And let's say that neither Bezos nor the Post challenges that. But let's say that you represent clients who really like the Post as it was, who really want to keep receiving the Post, who really want to publish op EDS in the Post. Would you have standing? Like, what kind of a claim would you be making there? I believe so, Justice Baird. And the Court has cited Lamont in other cases in more recent years to say we've recognized a right of American listeners to receive information from others. And remember, even that is a lot. That's only a small part of the argument I'm making on behalf of the creators. You know, I don't mean to diminish Mr. Francisco's arguments on behalf of the company and ByteDance, but the core speech in front of you in this case are the videos and other forms of communication that people like my clients are posting by the millions every day. On this platform to share with other Americans. Can you win? If is it possible for you to win and Mr. Francisco to lose or you rise or fall together? No, I think it's possible. I mean, I don't think we should. But was it possible for you to win and him to lose? Let me put it this way. If you were to conclude that something about the corporate ownership structure, and I think there's some conversation about this earlier impeded Mr. Francisco from being able to assert full throated First Amendment rights in this case, I would step in and say, well, certainly we can do that and get you to the strict scrutiny. And then the arguments pretty much line up. Then you're in a question of can the government satisfy strict scrutiny? And, And I think, Mr. Chief justice, you asked about do we have cases for this and that? I think that the idea is yes, we have cases that say once you're in strict scrutiny, that regulating the content because you don't think it's going to be pro American enough or it's going to be too pro. Foreign interest is just verboten under the First Amendment. That's the history and tradition. And Justice Kavanaugh, when you asked about the broadcast cases, the ground did not just in scarcity, but they're grounded in scarcity in a particular way. It has to do with the absolute need Congress has for licensing in a world of scarce resources. And so that's the very small carve out that even in Turner, the court wouldn't extend to cable television that exists for broadcast licensing. And if you look on the 200 plus years of our country for any other example of foreign ownership of media being regulated by Congress, let alone being permitted in the case law, you are not going to find it. And I think the reason why is because everybody has understood that if you're not in a world of scarcity where licensing is impossible, you cannot give the government, and in this more extreme example, the President himself, unbridled discretion to choose who is a proper owner of a speech platform in this country. Because it is so hand in hand with viewpoint. As I said earlier, any number of owners of big media enterprises, whether they be Americans or foreign citizens, could be accused of having a particular viewpoint. But speakers who engage in those platforms have choices they can make. And so on behalf of our creator clients, we find it not at all satisfactory to be told, well, look, just go post somewhere else. It's not enough to tell a writer, well, you can't publish an op ed in the Wall Street Journal because you can publish it in The New York Times instead, just like here to say you can publish it on Instagram or some other platform, not just TikTok. TikTok has a distinct editorial and publicational perspective, and it particularly benefits people like my clients who are not famous people. They're not actors from Hollywood who have a lot of people following them. They're ordinary American citizens whose content that they create on the platform gets privileged by way of the quality of that content, and that's what's so powerful about the platform. So whether you're an ordinary American citizen, or I might add, whether you're a presidential candidate in our last election, if you want to reach new and different audiences, TikTok is the place people go. This may not make any difference for constitutional purposes, but just out of curiosity, I'd like you to explain what the practical consequences would likely be for your clients if TikTok went dark. As Mr. Francisco put it, there, I assume, is a great demand for what TikTok provides. And if TikTok was no longer there to provide what your clients really want, is there a reason to doubt that some other social media company would not jump in and take advantage of this very lucrative market? There are two reasons, Justice Alita. One is many of the declarations from my clients actually explain. They've tried on other platforms to generate the kind of audience and engagement they've been able to on TikTok, and they've fallen dramatically. Yeah, I know. They haven't so far. And I'm just. You know, I'm just wondering whether this is like somebody's attachment to an old article of clothing. I mean, I really love this old shirt because I've been wearing this old shirt, but I could go out and buy something exactly like that, but no, I like the old shirt. Is that what we have here? Or is there some reason to think that only ByteDance has this can? ByteDance has devised this magical algorithm that all of the geniuses at Meta and all of these other social media companies, they couldn't. No matter they put their minds to it, they couldn't come up with this magical thing. I think empirically, they. Otherwise, other companies have been trying for a few years to catch up with TikTok and replicate it, and have been very unsuccessful. And so that ought to tell you something. And so just imagine the algorithm here as a collection of thousands of editors. You know, imagine the floors of an office building being filled with a collection of editors. You could imagine a situation where that collection of genius that is on a particular floor cannot be replicated. By another group of people. And that's kind of what you have here. I understand that. Thank you, Council. Justice Thomas, Anything further, Justice League? Yeah, one other question. I'm intrigued by your Mount Healthy Hunter versus Underwood argument. I mean, maybe you're right, but Mount Healthy arose in an entirely different context, where you're trying to get to an employer's motivation. Hunter vs Underwood involved an extreme situation where the Court looked at the records of a state Constitutional convention and came to the conclusion, apparently, that racism was the only motivation for what was done. But it does seem to me to be potentially quite unworkable and contrary to what we've generally said about legislative intent to apply the now healthy framework to a congressional enactment. Do you recognize or do you acknowledge that that would be very difficult? Because when an act of Congress is passed, there could be more than 250 different motivations for the votes that were cast by the members. Yeah, I totally understand that. And in Hunter, the Court actually engaged with that problem to some degree. And what Hunter said is, to avoid that problem, we're going to look just to two things. One is the State's brief, which I'd say is the Solicitor General's brief by comparison here and the text of the law. And here, that's the only thing I need to rely on to get you to the place that they wouldn't have enacted. Well, it gets you to the place that this was part of what motivated Congress. But why does it get you home? Well, particularly when there's a severability clause in this act, it can't be only part of it. It has to be enough to sustain the entire act, or at least the parts that you wouldn't sever from the Act. And so I think the reason why is because it's not just the content recommendation algorithm part that can be theoretically, I guess, severed out. It's also the covered company provisions, and it's just the whole equation approach of the statute that is based on content, not on data security. All right, thank you. So, okay. Justice Sotomayor. No, I'll save it for the sg. Justice Gorsuch. Justice Captain Justice Jackson, one quick question. You. You repeatedly say that the, from your perspective, the government's motivation is that the content might be too anti American or too pro China, et cetera. So that's why you think this is a content based restriction. But I guess I'm curious if you would say the same thing if the government had articulated its rationale as saying, you know, our motivation is to limit foreign interference in American social Media platforms or discourse. Isn't that a different motivation from the standpoint of how we characterize this? I agree. But then the question I would ask if the government said that, which I think kind of in the reply brief, maybe the government does say that, is that how on earth are you then serving a national security interest? You know, if all you're doing is just saying we don't like a foreign country rearranging cat and dance videos, like it's hard to come in and make a national security argument. So the only way you get to national security, which is the government's own argument, is to look at the substance that's being rearranged and say we don't like the way the substance is going to be rearranged and and curated differently. Thank you. Thank you, Counsel. General Prelogar, Mr. Chief justice, and may it please the Court. The Chinese government's control of TikTok poses a grave threat to national security. No one disputes that the PRC seeks to undermine U.S. interests by amassing vast quantities of sensitive data about Americans and by engaging in covert influence operations. And no one disputes that the PRC pursues those goals by compelling companies like bankdance to secretly turn over data and carry out PRC directives. Those realities mean that the Chinese government could weaponize TikTok at any time to harm the United States. TikTok collects unprecedented amounts of personal data. And as Justice Sotomayor noted, it's not just about the 170 million American users, but also about their non user contacts who might not even be engaging with the platform. That data would be incredibly valuable to the prc. For years, the Chinese government has sought to build detailed profiles about Americans. Where we live and work, who our friends and coworkers are, what our interests are, and what our vices are. TikTok's immense data set would give the PRC a powerful tool for harassment, recruitment and espionage. On top of that, the Chinese government's control over TikTok gives it a potent weapon for covert influence operations. And my friends are wrong to suggest that Congress was seeking to suppress specific types of content or specific types of viewpoints. Instead, the national security harm arises from the very fact of a foreign adversary's capacity to secretly manipulate the platform to advance its geopolitical goals in whatever form that kind of covert operation might take. The act addresses the threat of foreign adversary control with laser like focus. It requires only divestiture of TikTok to prevent Chinese government control. And that divestiture remedy follows a long tradition of barring foreign control of U.S. communications channels and other critical infrastructure. So no matter what level of first amendment scrutiny applies, this act is valid because it's narrowly tailored to address compelling national security threats. Now, my friend Mr. Fisher just emphasized, and I acknowledge that millions of Americans enjoy expressing themselves on this platform, but the important thing to recognize is that the act leaves all of that speech unrestricted. Once TikTok is freed from foreign adversary control, the First Amendment does not bar Congress from taking that critical and targeted step to protect our nation's security. I welcome the court's questions. Is there any difference between content manipulation by a non U. S. Company as opposed to a US company? I didn't hear Mr. Fisher make a distinction between the two. Yes, and I think the important thing to recognize is that the act here is targeting covert content manipulation by a foreign adversary nation. Now, I understand, my friends, what difference does that make? The difference is that there is no protected first amendment right for a foreign adversary to exploit its control speech. The difference between covert and non covert. So I think that Congress's concern with the covert operation was that a foreign adversary could effectively weaponize this platform behind the scenes in order to achieve any number of geopolitical goals. Here, here are some of the examples that come to mind. One of the pages out of the playbook here is for a foreign adversary to simply try to get Americans arguing with one another to create chaos and distraction in order to weaken the United States as a general matter and distract from any activities that the foreign adversary might want to conduct. On the. What do you mean by covert, though? I mean, is covert just mean it's hard to figure out how the algorithm works? Because we could say that about every algorithm. No, the COVID nature of it comes from the fact that it's not apparent that the PRC is the one behind the scenes pulling the strings here and deciding exactly what content is going to be made to appear on the site. And another way that this. It's just because we don't know that China's behind it. That's what covert means. Well, I think it doesn't have anything to do with the difficulty of figuring out what the algorithm is doing. It's just because people don't know that China is pulling the strings. That's what covert means. What it means is that Americans are on this platform thinking that they are speaking to one another and this recommendation engine that is apparently so valuable is organically directing their speech to each other. And what is covert is that the prc, a foreign adversary nation, is instead exploiting a vulnerability. Vulnerability in the system. Well, if that's all it means. Like people don't know that China's behind it. Like everybody now knows that China is behind it. But it's the specific, the specific content that's being manipulated would be unapparent. And so that's true of every search engine. I mean, you can, you can take any of these algorithms, whether it's X or whether it's, you know, you name it. What are the new ones? Blue Sky? I mean, none of these, none of these are apparent, right? You get what you get and you think that's puzzling and it's all a little bit of a black box. So you can't just mean it's a black box, it's covert. They're all black boxes. And if you just mean what's covert is the fact that there's China behind it. I mean, honestly, really, like everybody does know now that there's China behind it. So I just don't get what this covert word does for you. I think the problem with just saying as a general matter, China has this capability and might at some point be able to exercise it and manipulate the platform is it doesn't put anyone on notice of when that influence operation is actually happening and therefore it doesn't guard against the national security harm from the operation itself. Isn't that a pretty paternalistic point of view? I mean, don't we normally assume that the best remedy for problematic speech is counterspeech? And TikTok says it could even live with a disclaimer on its website saying this can be covertly manipulated by China in case anybody were left in doubt after today about that possibility. So you're saying that won't work because that won't work because it is such a generic generalized disclosure that it wouldn't put anyone reasonably on notice about when it's actually happening. The example I've been thinking about is argument is that the average American won't be able to figure out that the cat feed feed he's getting on TikTok could be manipulated, even though there's a disclosure saying it could be manipulated. But imagine if you walked into a store and it had a sign that said one of 1 million products in this store causes cancer. That is not going to put you on notice about what product is actually jeopardizing your health. And I think that's roughly equivalent to the type of disclosure they're contemplating here. They brought up the example of the Foreign Agents Registration Act, Farah there. You have to disclose the actual content. If that's true, then that wouldn't that be true for all social media companies, for all content? I mean, every editor, every newspaper in its editorial room makes decisions about what it's going to run and how it's going to say it. And every algorithm has preferences, whether it's domestic or foreign. And nobody really knows exactly when those editorial decisions are being made or how, but they're generally aware, and we think that's enough. I think, though, that there is a real risk that when a foreign adversary has control of that kind of mechanism and a speech platform in the United States, it could weaponize that platform to harm United States interests. And one of the key ways that the PRC flexes this muscle is to suppress speech. General, I'm sorry to interrupt you, but again, I'm not. We're not arguing about the compelling interest. We're arguing about the tailoring. Right. And so I guess what I would say you began by saying the cure for concerning speech is counterspeech. Here I dispute the premise that Congress was specifically concerned about any particular subject or any particular viewpoint. It wanted to close off a capability of a foreign government. But in any event, it's very hard to engage in counterspeech when you don't know because someone is secretly manipulating the platform behind the scenes and in particular what the PRC has the capability to do. Simply silence American Voices paper owned by a foreign company and a foreign government. You wouldn't know when it's exercising editorial discretion about this article or that article or how it's doing it. So maybe we just need to shut down the Oxford University Press in America or you picket any other foreign owned politico I was told today is owned by Germany. That would all be okay on your theory so long as Congress designates that country a foreign adversary. We are not asking the court to articulate bright line rules, rules to govern all kinds of situations. I am testing your argument. Yes. And what I want to acknowledge is that sometimes the court has recognized that a speaker based preference might reflect a content based preference. And in the context of ownership of a newspaper, for example, in part because a newspaper is a one way channel of communication and is generally understood to represent to some extent its publisher's views, maybe the court would more readily infer that a regulation targeting that is actually aiming to target content. But I don't think about the same. I'm not talking about the compelling interest or anything. I'm talking about the tailoring. And you're saying we have no alternative but to stop this speech altogether. We can't rely on disclosure. But you say that wouldn't apply to Politico or to the Oxford University Press because in the circumstances where you have a newspaper that is understood to reflect its publishers views, then you might think that disclosure would be a more adequate remedy there because it's not just holding itself out as a forum for speech between other people. I think social media platforms do raise distinct interests in this regard because what people think when they're engaging with TikTok is that it's organically feeding them videos based on the recommendation engine. And if actually China is behind the scenes engaging in this kind of collaboration, covert operation, it does prevent a distinct national security risk. Of course, the other big difference with the newspaper is it's not likely to be collecting sensitive personal information about 170 million-plus people and then having the capacity to send that back to a foreign adversary. General Prelover, can I. Oh, go ahead. I was just going to say, did I understand you to say a few minutes ago that one problem that bite is that ByteDance might be through TikTok trying to get Americans to argue with each other, that it might be just trying to. If they do, I say they're winning. That might very well be true, Mr. Chief Justice. And I think the point I'm trying to make is that China is a foreign adversary nation that looks for every opportunity it has to weaken the United States and to try to threaten our national security. And if it has control over this key communications channel, it's hard to predict ex ante exactly how it's going to use that as a tool to harm our interests. But we know it's going to try first and foremost by seeking to get the data of these American users, which would be of a piece of all of the activity that PRC has already undertaken to breach our laws, hack opm, for example, and exfiltrate the background files and security clearances of 20 million government employees. The breach of Equifax to get sensitive financial data, Anthem to get sensitive health care data. We know that the PRC has a voracious appetite to get its hands on as much information about Americans as possible. And that creates a potent weapon here because the PRC could command that ByteDance comply with any request it gives to obtain that data. That's in the hands of the US subsidiary. Thank you, General. Suppose that TikTok had no connection whatsoever with any foreign government. It was owned instead by an immensely, immensely rich multinational corporation. And Congress concluded that this multinational corporation really has it in for the United States and is going to use this extremely popular platform to do everything it can to undermine the United States. And all the ways in which you think that TikTok made may pursue at the direction of the PRC with this, would that be the same case? I think there would be a first order question of whether the multinational corporation itself has First Amendment rights. It's an American corporation. So if it were an American corporation, I think that and Congress disagreed with the viewpoints or content the corporation would display. Obviously that's an direct regulation of protected speech and it would trigger strict scrutiny. I think that's different in kind from what Congress was worried about here, which was not regulating speech as such, but instead regulating foreign adversary control. So your whole, your argument depends on the fact that what is at bottom here is the. The People's Republic of China using TikTok. That's what your argument depends on. If this were an American corporation. Corporation be an entirely different thing. Exactly. And the reason we know the statute is different is because all of the same speech that's happening on TikTok could happen post divestiture. The act doesn't regulate that at all. So it's not saying you can't have pro China speech, you can't have anti American speech. It's not regulating the algorithm. Tick tock, if it were able to do so, could use precisely the same algorithm to display the same content by the same users. All the act is doing is trying to surgically remove the ability of a foreign adversary nation to get our data and to be able to exercise control over the platform. I just wanted you to respond to Mr. Fisher's argument about the rights of Americans to receive information, say from the PRC or anyone else, and that even if ByteDance did not itself have First Amendment rights, that Americans would have a First Amendment right to. To receive that information. In the Lamont sense, yes. So I think that Lamont reflected a principle that there can be a right of American listeners to receive information. And if Congress is directly regulating that based on disagreement with the speech that's being sent into this country, that's obviously going to trigger height and scrutiny under the First Amendment. But here I think the users have to be asserting a different type of interest because what Congress was safeguarding against was not the ability of TikTok to continue to operate or the users to post content. It was focused only on foreign adversary control. And so the users would have to demonstrate that they have some unqualified First Amendment right to post on a platform that's controlled by a foreign adversary which could use that access to then threaten our nation's security by gathering data on tens or hundreds of millions of Americans and also use it for covert influence operations of whatever form. And I don't think there's a First Amendment right to do that. I was trying to think of whether there's a historical analog here, and this is what I came up with. And you can tell me whether it's fallacious. You know, in the mid 20th century, we were very concerned about the Soviet Union and what the Soviet Union was doing in this country. And the Communist Party of the United States at that time was integrally attached to the Communist International, which was essentially a Soviet operation. Right. So if Congress had said, oh, it's very nice, we can have the Communist Party usa, but it has to divest, it has to completely divorce itself from the Comintern and from any international ties that it has, do you think that that would have been absolutely fine? And so if the answer is yes, yes, it would have been fine. It's not just like this case. Or if the answer is no, why is it not like this case? So I guess I think I would need to know more information about how the international organization is able to exercise control over the American affiliate and if it had the capacity, for example, to in an unqualified fashion, gather data from that affiliate in a way that was going to jeopardize our nation's security. I'm talking more about sort of the content. Let's put the data collection piece of this aside, which seems not very pertinent to my 1950s analog, but, you know, very concerned about the kind of speech that the Communist Party was making in the United States. And it turns out that that content was pretty well scripted someplace else. I think if it was specifically a concern about the content, then that would trigger heightened scrutiny under the First Amendment. We're not trying to run away from that principle here. Instead we're making, I think, a narrower argument. Well, then I think that you're a little. I think you've just given your thing away because content manipulation is a content based rationale. We think that this foreign government is going to manipulate content in a way that will, that concerns us and may very well affect our national security interests. Well, that's exactly what they thought about Communist Party speech in the 1950s, which was being scripted in large part by international organizations or directly by the Soviet Union. I disagree that the concern with COVID content manipulation is itself content based or that it looks anything like the kinds of laws this court has previously said are content based. The court most recently in City of Austin said you only, only have a content based law when Congress is setting out to discriminate against particular subject matters or particular viewpoints. So it's not enough that the law is is regulating in the space that involves content in some way. You have to have this motive by Congress, Congress to actually want to suppress speech on certain topics or certain viewpoints here. Congress just wants to cut the PRC out of the equation altogether and all of the same speech could continue to happen on the platform. It's like patching up a backdoor vulnerability that the PRC has that we can't totally see around all the corners to imagine how it could use it against our interests. But we know the PRC will do whatever it can to try. And I think that is different in kind from imputing to Congress some motive to specifically get more speech on certain topics or with certain viewpoints. This law was passed by broad bipartisan majorities in both houses of Congress and our legislatures and our legislators don't always agree on everything. I think it's unlikely that all of them had exactly the same views about what's good content on TikTok or what are good viewpoints. They weren't united on that. What they were united around was the idea that it is a grave threat to our nation. If the PRC can itself behind the scenes be controlling how this platform operates, why doesn't this act classify on the basis of speaker? I do think that when it comes to the PRC and ByteDance, you could treat this as a speaker based restriction. And aren't speech speaker based restrictions almost always viewpoint based restrictions, Content based restrictions? The court has said it depends. It hasn't applied an inflexible rule that anytime you are regulating certain speakers you are invariably regulating based on content. Instead, the court has said it warrants closer consideration. And here if you look at the US speakers, TikTok, us and the users, none of them are being regulated in a way that suggests its disagreement with their content. It's all about what our foreign adversary is doing. It's hard for me to, it's hard for me to think of situations, maybe they exist where our classification based on speaker is not viewpoint or content based restrictions. And somebody says, Joe can't talk anymore. We're going to shut Joe up. And we don't know what he's going to say tomorrow or two weeks from now. We don't know what he's going to discuss. But whatever he says is bad because Joe is a bad person. I mean that's, that's viewpoint and content based, isn't it? I think when it comes to a foreign adversary, it's not right to view it that way. And the reason for that again is this, this is a sophisticated adversary nation and we can't just simplistically say, oh, what the PRC is going to want is to see more pro China content on this app. As Chief Judge Srinivasan observed, there are various ways that the PRC could try to create some kind of false flag operation and actually promote anti China content not to dictate how Americans should think about things, but simply to create some trumped up justification for a military or economic action that the foreign adversary wants to take against us. And I don't think a concern with trying to ward off that capability viewpoint or content. Still we don't know what the content is going to be, but we know it. Joe, is bad because I think the better classification is to recognize that what we're trying to prevent is not the specific subject matter, the specific viewpoints, but the technical capability of a foreign adversary nation to use a communications channel against this. I guess I'm just struggling how covert content manipulation isn't content based restriction. So it's kind of hard to avoid the word content and it's kind of hard to avoid the word viewpoint here, isn't it? I don't dispute that it's related to content, but I don't think it reflects Congress seeking to set out in advance what kind of speech we should have reflecting certain views on certain topics. Instead, it's about trying to close off a vulnerability that our foreign adversary nation could exploit. And I would be remiss if I didn't point out that even if you thought this was content based, all that means is that we're in strict scrutiny. And as the D.C. circuit recognized here, we think that this law serves compelling national security concerns that sound in some of the same arguments I'm making here and that have a long standing correspondence to history and tradition of trying to prevent foreign control. And then we get to the question whether there's a less restrictive means. I get that. And whether disclosure might suffice on the data security point. Your friends on the other side make the argument that if that were the concern, Congress could ban TikTok us from sharing data with anyone on pains of penalties that would put people in prison and shut the company down in the future as the government did, for example, with Arthur Anderson. Why isn't that a less restrictive means available? So I was surprised to hear petitioner offer that up today because there was a long course of discussion between the executive branch and bytedance and Tick Tock leading up to Congress's enactment of this act that spanned over four years, an extensive conversation about what limitations could be placed to protect Americans data. And it was never a suggestion that there would be any way to create a true firewall that would prevent the US subsidiary from sharing data with the corporate parent. And the reason for that sounds in the technological features of this application. I think there can be no reasonable dispute that the source code development and the maintenance of this algorithm rests in China, which is why China has sought to try to control export restrictions with respect to the algorithm. And what that means is you, you need substantial data flows between the companies in order to continue to modify that algorithm, refine it and so forth. So I don't think that that was an option ever on the table, including with respect to the proposed National Security Agreement that was insufficient in protecting our data privacy and security concerns. That didn't come across enough in the briefs. If we are in the world of data protection as opposed to content material content control, I think the it's hard to get around the post of virtue divestiture provision that says you can't do business with them on the algorithm because that very much is content based, it's a content based restriction. But what you're saying is you can't do it for a data control reason, meaning that you can't really run their algorithm without sharing the very data that we are concerned about as a threat, correct? That's right, Justice Sotomayor. And you don't have to take my word for it. You can look at the specific terms of the national security agreement that ByteDance itself proposed. The relevant definition of the accepted Data is at JA239 to 240. And a reference statement is categories of information that would of necessity, technological necessity and business necessity have to flow back to China. And the relevant categories are in the sealed appendix. But I would really encourage the court to look this up because it's eye opening. It is at the Court of Appeals sealed Appendix 249 to 252 and 254. If you look at that information, it was a wealth of data about Americans that was going to have to go back to China in order for the platform to just continue its basic operations. And there's a legitimate commercial justification for that. But it creates this gaping vulnerability in the system because once that data is In China, the PRC can demand the ByteDance, turn it over and keep that assistance secret. And the one final point on this is that ByteDance was not a trusted partner here. It wasn't a company that the United States could simply expect to comply with any requirements in good faith. And there was actual factual evidence to show that even during a period of time when the company was representing that it had walled off the US Data and it was protected. There was a well publicized incident where ByteDance in China surveilled US journalists using their location data. This is the protected US data in order to try to figure out who was leaking information from the company to those journalists. General, you want us to look at that and you get to look at it, but your friends on the other side don't get to look look at it. That doesn't seem fair. That's the sealed appendix, Mr. Chief Justice. So it's their information. They can look at it. It's just under seal to protect their proprietary business information. General so I want to go back to the discussion about content discrimination and we're going to shut Joe up here. It seems to me like we are saying to bite dance, we want to shut you up. And so let's say that I think that that is content discrimination based on speaker. Tell me if, if I think that, tell me if I have to conclude that it is also speaker based discrimination and content based discrimination for TikTok. No, it is not. And the reason for that is because it would be an anomalous principle to say that an entity outside the United States that can't assert its own First Amendment rights can somehow manufacture that right through the expediency of forming a US Subsidiary, especially one that it wholly controls. So you don't have have to stand on that argument that you were having with Justice Alito and Justice Gorsuch to still have your point about content discrimination. That's right. And I think if you're focusing in on the relevant US entities here, TikTok US and the users themselves, this act isn't regulating them in any way. It's not trying to dictate the algorithm that TikTok US can use. And in fact Congress, I think was doing everything it could to preserve access to TikTok in the United States in recognition that a major Americans enjoy expressing themselves and building community on the site. Sorry, just one last question. Justice Gorsuch had asked your friends on the other side whether the new administration on January 20 could extend the deadline. What's the your position on that? So I think it tees up a statutory interpretation question of whether there can be an extension after the time period for divestiture has lapsed. I would think the Court might start with its decision in the Hawley Frontier case, which did recognize the ability to get an extension after a lapse like that. So it's your position that they could we have not run it to ground in part because it's simply not presented here. And I'm not prepared to take a position on that statutory interpretation question. I do want to emphasize, though, that my friends have pointed to January 19 or nine days from now as a moment when tick tock might go dark. At the outset, of course, Congress was hoping, hoping to prompt a divestiture. But I think the more important thing to focus on now is that even if that were to happen, Congress specifically anticipated it and provided authority to lift these restrictions as soon as there's a qualified divestiture. And the reason for that is because foreign adversaries do not willingly give up their control over this mass communications channel in the United States. And I think Congress expected we might see something like a game of chicken by dance saying, we can't do it. China will never let us do it. But when push comes to shove and these restrictions take effect, I think it will fundamentally change the landscape with respect to what ByteDance is willing to consider. And it might be just the jolt that Congress expected the company would need to actually move forward with the divestiture process. So it's not irrevocable. That's an interesting point. And I hope Mr. Francisco or Mr. Fisher, whoever is delivering the rebuttal, will address it. So if we were to affirm and TikTok were forced to cease operations on January 19th, you say that there could be divestiture after that point and TikTok could again begin to operate the way. Continue to operate. That's exactly right. There's nothing permanent or irrevocable that happens on January 19th. And I think that Congress might have thought that we get in a situation here where a foreign adversary is doing whatever it can to just not comply. It's hoping the United States is going to blink first through our court system or through the executive branch getting cold feet about enforcing the law. But Congress set a deadline, and I think it thought that deadline would have a forcing function. Let me ask you a question about your. Your effort to draw a distinction between ByteDance's speech and TikTok speech. So suppose that the. The people Support of China funds a movie and there is an entity in the United States, a US Corporation, that thinks, wow, this is a great movie, and while the PRC would not have a First Amendment right to show it in the United States, would you Say that the American company would not have the First Amendment right to do that because whatever expression there is in that movie, it's the PRC's expression, it's not their expression. No, no. I wouldn't make that argument. And I want to be really clear. I thought that was the argument that was being made. No, no. So our argument is that this is not a direct regulation of protected speech in the first place, or at most it would warrant intermediate scrutiny because of the indirect effects that it might have on the American users or on the US Subsidiary. We're not suggesting that if Congress sought to directly regulate and prohibit speech in the United States based on concerns about its content center viewpoint that's somehow immune from First Amendment scrutiny just because it comes from a foreign source, obviously that kind of law is going to trigger strict scrutiny. And I imagine it would be a different constitutional analysis because it's hard to imagine the same profound national security harms that would exist in that scenario as compared to what we have here. Thank you. General, isn't the whole point of the divestiture requirement that the content on TikTok would be different if it was owned by a different company? I'm still struggling with your insistence that this is content neutral versus content based when we have that kind of circumstance. The reason that I am continuing to try to hold the line on that is because there is nothing in the act that would directly dictate any different mix of content on Tick Tock. The US Subsidiary could use the same algorithm, show the same content by the same users in exactly the same order. It's not about trying to interfere with the US Subsidiary's exercise of editorial judgment in any relevant sense. Instead, all Congress was doing was homing in on the problems of having a foreign adversary be able to interject itself and be able to harvest your data. On the other side, say that the motivation for doing that is because the foreign adversary might influence or change the content. So content is. I mean, content matters, doesn't it? I certainly. I think that content was relevant to Congress's concern about an adversary having control over the communications channel. I think not. Again, because of any particular concern about viewpoints or subjects. But just relevance. Isn't that relevance enough to trigger at least some scrutiny? Scrutiny with a heightened scrutiny. From the standpoint of our legal tests, I certainly understand that intuition. And if the Court thought that it were prudent to simply try to rule narrowly here and not dictate broader First Amendment principles, we have no problem with the Court assuming that heightened scrutiny applies. We think the law easily satisfies it. We do think that intermediate scrutiny is a more appropriate framework for this kind of law that's not directly targeting protected speech. But in any event, there's a compelling, compelling national security interest here. And the law isn't just narrowly tailored, it's precisely tailored. It's trying to fix the thing that's creating the problem, which is the PRC's involvement and the Chinese government's ability to exercise this control over the corporate entities. How are we supposed to think about the two different rationales here and how they interact? The data collection rationale, which seems to me at least very strong, the COVID content manipulation rationale, as the hypotheticals have illustrated, raise much more challenging questions for you about how far that goes. And if that alone, if you didn't have the data collection piece, you only had the COVID content manipulation piece. And then Mr. Fisher's point, Mr. Francisco's, that Congress would not have enacted this just based on the data collection rationale alone. Just your understanding of how the two arguments fit together. Sure. And let me walk through our defense of the data protection rationale and why we think it's a full justification for this law. And the court could stop there and then be responsive to their arguments that somehow the interest in preventing covert manipulation somehow taints it. So, just on data protection, I think that it should be beyond dispute that of course our nation has an enormous interest, interest in keeping the sensitive data out of the hands of our foreign adversary. And it should also be beyond dispute that our foreign adversary has an existing capability, through its laws and through the way that these companies are integrated, to get its hands on that data. There is no question that Congress was sincerely motivated by that concern. There's a whole lead up to the statute here where the Executive Branch, across two different presidential administrations, was expressing concerns about the data problems. Congress was extensively briefed on those problems. It passed a companion data protection statute at the same time that was intended to prevent selling data to foreign adversary nations. The statute is shot through with protections that I think are key to this concern about closing off the vulnerability of access to the data. So that's a sincere justification for Congress's desire here to act. We think it's a compelling interest and it's narrowly tailored. Then you get to the question, question of what to do about the fact that there's also this interest in covert content manipulation. And in the First Amendment context, this court, in cases like Hefrem, has made clear that once you have a justification that satisfies the First Amendment, you don't need to go further and look at other justifications to decide whether they would independently satisfy First Amendment scrutiny. So I think it's not necessary for the Court to go on and probe whether it thinks that covert content manipulation is itself independently justifies the law. Now my friends say that's all fine and good, but they think covert content manipulation is just per se illegitimate. And I honestly don't understand how that argument could carry the day. Because just imagine if Congress passed a law that said the PRC can't covertly manipulate TikTok. Obviously that law is not going to violate any constitutional principle. It's a laudable goal, I think, for our legislature to protect us from foreign adversary interference like that. And so there's nothing, something, there's nothing that's inherently impermissible about wanting to guard against that risk. Maybe you could say that it sweeps in too much protected speech in the way it's operationalized in the act here. But there's certainly no fundamental taint or anything akin to racial discrimination to call into question whether Congress could seek to vindicate that as one of many interests. So I guess to just kind of bring it all together, what I would say to the Court is they have basically acknowledged that data protection is a compelling interest. That was Congress's real interest. It provides a sufficient basis on its own to uphold this law. The Court could say just that and and affirm. I don't know how we do that unless we accept your argument that the post divestiture provision that stops them from conferring on the algorithm is not a speech impediment. Meaning it's very hard for me to say that it's not motivate to decide that question, that it is a speech impediment and one that on its face itself has to be analyzed separately from the data. So justice let me begin by saying again that we do think that an interest in preventing any operational agreement between the US subsidiary and ByteDance, which is the relevant provision you're talking about, is justified by data protection alone. And that includes with respect to cooperation on a content recommendation algorithm, specifically because of the concern that it necessitates data flows between the companies. So I think that as a factual matter that could justify Congress in acting. But to the extent that you think that actually the prohibition on coordinating with respect to an algorithm reflects some kind of impermissible content based problem with the statute. The statute has a severability clause and I certainly don't think that it would give the Court a basis to invalidate this law or to stop it from operating with respect to all of the provisions that operate to protect data security, at most it would would suggest that that little piece of the law has to be on its own severed from the rest of how the statute operates. How does that affect whether we would apply? Because assuming it's data protection, then I would think that strict scrutiny wouldn't necessarily apply. I could understand applying intermediate scrutiny, but how do we do that with respect to this part, the algorithm issue? How do we get to intermediate scrutiny with respect to that? The way you get to intermediate scrutiny there is to recognize that prohibiting foreign adversary control over the operations of the platform, including with respect to the fundamental backbone of the system, is not based on any protected speech or, or content based in the relevant sense. I've been thinking of it as akin to something like a piece of software you might have on your phone that would allow the Chinese government to listen in on every American conversation. If Congress wanted to enact a law that patched up that vulnerability and said you can't use that piece of software or you can't coordinate with Chinese companies with respect to it, clearly we would recognize that closing off that capability of China is a laudable and in fact compelling government interest. And I think when it comes to the risks that foreign adversary control pose here, it's similar in kind. It's simply trying to prevent access by the Chinese government to the TikTok system writ large. And that includes through the use of the algorithm. Thank you. Could the President say that we're not going to enforce this law? I think as a general matter of course, the President has enforcement discretion. Would that then adequately, would that be binding? In other words, protect the regulated community so they could rely on that under due process principles going forward? That raises a tricky question. So I think there would be adequate. Well, I think, I think there is a strong due process argument that the third party service providers could invoke if there were enforcement action based on a period of time when the President said the law wouldn't be enforced. The kind of. They're not going to take that risk unless they have the assurance that a presidential statement of non enforcement is in fact something that can be fully relied on because the risk is too severe otherwise. Right. I think that they might judge that based on this court's precedent in the due process space and principles of entrapment by estoppel, maybe they have a sufficient safeguard here to allow them to continue to operate. I would think even before a non infection enforcement policy were announced, of course the President elect would want to review all of the updated national security information that has come in over the last four years that undergird Congress's judgment here. But the final thing I would say is that even if you think the third party providers are simply going to choose not to continue to provide these services because it's too much of a risk to take on, again, that's not anything permanent or irrevocable. And that might be just what the PRC and ByteDance need to start taking seriously some of the public reporting about interest in acquiring the company. At one point, Mr. Francisco suggested that what we might want to do and what he would regard as certainly preferable to a decision affirming on the merits was is to issue an injunction pending, I guess, consideration of what we now regard as the. As the cert petition that was filed here. What do you think of that suggestion? So I think this court doesn't have any basis to enter a temporary injunction unless it thinks petitioners are likely to succeed on the merits of the First Amendment claim. And to be honest, you know, I would. I think that there is no argument to be made that you should find that likely success. This is an act of constant Congress. This isn't some unilateral action by the executive branch, but it actually was action in parallel between the executive and Congress where Congress took action to close up a loophole in some of our laws. The executive had tried to force divestiture of tick tock under the Trump administration, but that had gotten tied up in litigation about those authorities. So Congress came in and provided additional authority based on a substantial record, including with respect to the data harm. And I don't see any basis for this court to displace the deadline that Congress set without finding that actually there is a potential First Amendment problem here. Do you think we have the authority to issue an administrative stay as we have done in other cases, or do you think that the January 20th deadline prohibits us from doing that? I don't think this court has a formal basis to not issue an administrative stay if it believed that that was necessary to. To assist in the court's own consideration of the case. And I would obviously defer to the court and whether it has a sufficient time to resolve the case. But we are here ready to submit the case today. And I think it is in the interest of Congress's work and our national security to resolve the case and allow the statute to take effect. Can I just test your. To see whether your recollection of what Mr. Francisco said about a warning is consistent with Mine. I did not hear him say he can address this in rebuttal, that it would be acceptable to his client if Congress had said there has to be a stark warning on every TikTok. Such as warning the communist China is using TikTok to manipulate your thinking and to gather potential blackmail material. Did you hear him say that that would be okay? I don't think he's made that concession. But even if he had, I don't think that would address the government's national security concerns. And one of the points here is that it's not just data privacy. So even if you could somehow put users on notice that the PRC could obtain their data and they choose to disregard that, it's not a data privacy interest. It's a national security interest. There's a distinct sovereign harm to the United States if our foreign adversary can collect this massive Data set, about 170 million Americans. And as Justice Kavanaugh touched on, you know, there are a lot of teenagers using TikTok today who might ignore a warning like that and not really care, but they're going to grow up, and they might become members of our military, they might become senior government officials. And for the. The Chinese government to have this vast trove of incredibly sensitive data about them, I think obviously exposes our nation as a whole to a risk of espionage and blackmail. Thank you. I did want to touch briefly on the questions about history and tradition here, because my friends have said several times that the Communications act of 1934, which we think is roughly analogous to the type of restriction that Congress was seeking to enact here, is justified entirely by concerns about scarcity, how you can't have sufficient bandwidth. And I, of course, recognize that scarcity is what created the need for a licensing regime in the first place. But I think it's important to clarify the historical record here that in choosing to limit foreign control of radio stations, of broadcast stations, Congress specifically cited a concern about national security that is written into the statute. National defense was one of the listed purposes of having that kind of restriction. And so I don't think my friends can succeed in being dismissive of that concern about history and tradition and what it shows about the national security judgments that undergird this law. The one other factual point I wanted to make, to be responsive to a few points that my friends have touched on, relates to whether TikTok US has the ability to alter this algorithm, whether divestiture is feasible, how ByteDance has manipulated the platform in the past. With respect to the algorithm. I think we're Simply talking past each other. We don't dispute that TikTok US might engage in some functions in the United States to customize the algorithm for a US audience. The thing we're worried about is happening long before that over in China, where ByteDance is developing the source code, creating the basic backbone and functioning of the system, and is then blasting out the algorithm for use by the various subsidiaries in their home country. So we're not seeking to regulate any activity that TikTok US is engaged in here. Instead, what Congress is doing is trying to close off the vulnerability of PRC access abroad with respect to the feasibility of divestiture. My friends have said it would have been impossible to do this within 270 days. You know, at the outset, obviously there's no inherent impediment to divesting a social media media company. We just saw Elon Musk buy X or Twitter in about six months from offer to completion. And even with respect to this particular company, I think my friends are not well positioned to complain about the timeline because they've been on notice since 2020 that unless they could satisfy the federal government's national security concerns, divestiture might be required. But in any event, I don't think that the court should fault Congress for trying to balance competing interests here in making sure that there was a period for compliance and trying to preserve access to the platform for Americans while taking steps to safeguard against the risk to national security. Finally, with respect to the question of whether ByteDance has taken action on the PRC's demands, there is evidence in the record that Congress consulted to demonstrate that Outside of China, ByteDance has taken action to misappropriate data at the PRC's request that included efforts to track dissidents in Hong Kong, protesters there to track Uyghurs in China itself. We know that ByteDance has misappropriated US data with respect to surveilling of US journalists, and there was evidence in the record reinforcing the conclusion that ByteDance has been asked by the PRC to undertake efforts to censor content and manipulate the platform at the behest of the Chinese government. So I don't think there is a factual basis to dispute the record that Congress had before it. If the court has no further questions. General, if I understood correctly, under President Elect's first term, he passed an executive order requiring divestiture, correct? That's right. And this, that was challenged in court and state as a result of him exceeding his executive power to do that. But this bill followed a bipartisan investigation, correct? Yes. That's right. I am a little concerned that a suggestion that a president elect or anyone else should not enforce the law when a law is in effect and has prohibited a certain action that a company would choose to ignore enforcement on any assurance other than the change in that law. But putting that aside on the 19th, if it doesn't shut down, there is a violation of law, correct? Yes. And whatever the new president does doesn't change that reality for these companies. That's right. How long is the statute of limitations in effect, assuming that they violated it that day and later continue to violate it. But how long does the statute of limitations exist for a civil violation of this sort? It would be a five year statute of limitations. Thank you. Thank you. Counsel, a rebuttal. Thank you, Mr. Chief Justice. For points, all of which go to why we think this would law law would fail whether you applied intermediate scrutiny or strict scrutiny. I'd like to begin with the least restrictive alternative. Simply prohibiting TikTok Incorporated from disseminating any of the sensitive user data to anyone, including ByteDance under the threat of massive penalties. That is is definitely a less restrictive alternative. Now, my friend pointed to the NSA negotiations. Well, the sensitive user data that we're talking about and that were of concern in the NSA negotiations were not the type of technical data that she's talking about. The NSA did allow certain types of nonsensitive technical data to go back and forth, but that wasn't anybody's concern. And as we say in 20 page 23 of our briefs, they simply cut off the negotiations without ever raising those concerns. But to be clear, if that's a concern, sweep that into the ban too. Put in that nonsensitive technical data into the ban too. We'll deal with that. It's a lot better than simply being forced to shut down. So that is most definitely a less restrictive alternative that would address data security. We talked about the under inclusiveness in TEMU and Shein, the two large E commerce sites. Justice Kagan, you might have seen TEMU during the Super Bowl. It was heavily advertised. It's one of the most popular E commerce applications in the United states. It's got 70 million users. Justice Sotomayor, you were asking what they collect. This is From Joint Appendix 339 to 343, the US China Economic and Security Commission Review Report. Shein relies on tracking and analyzing user data, draws on customer data and search history with the assistance of artificial intelligence algorithms. It requests users share their data and activity from other apps, including social media. So they apparently Go into your social media apps and suck up all of the information, because they're e commerce apps. They take names, addresses, and credit card information. If you look at the privacy policies on their website, they collect location data. It looks like they might even collect, at some level, GPS location data. So they collect massive amounts of data.3. Their mere covertness argument makes no sense for the reasons that the court explored. If mere covertness were the issue, a disclosure would make perfect sense. Yet they're not concerned about mere covertness. They're concerned, as my friend suggested, with getting Americans to argue with each other. Well, you know, as far as I can tell, that's what news organizations do in this country every single day. That's what we call editorial content. That's what we call content itself. And so it's trained directly on the content. But even if you thought somehow that the mere covertness were the issue, that definitely could be addressed through a risk disclosure. So the data sharing ban, the risk disclosure, those are obvious, obvious less restrictive alternatives. And had the government considered them and rejected them, we would be in a different position. But if you look at this record, those are two less restrictive alternatives that the government did not address at all. Whether you apply strict scrutiny or intermediate scrutiny, that is fatal. Because under both standards, restricting speech has to be the last resort, not the first one. And when you fail to consider less restrictive alternative alternatives, you fail under either standard. My final substantive point is we absolutely think this court has the authority to enter an administrative stay. I didn't understand, my friend to disagree with that. We think that given the enormity of this decision, given the complexity of this case, it would make perfect sense for this court to enter an administrative stay. I also think you could enter a preliminary injunction. Yes, likelihood of success is one standard, but you don't have to determine ultimate success. And as you do in other related contexts, like with respect to stays, you often make clear that you are not addressing the merits of the case. I think you could do that here. The bottom line, your honor, is this case ultimately boils down to speech. What we're talking about is ideas. And my friends on the other side, when you cut through everything else, are ultimately worried that the ideas that appear on the TikTok platform could, in the future, somehow manipulate Americans, could somehow persuade them, could somehow get them to think something that they ought not be thinking. Well, that whole notion is at war with the first amendment. If the first amendment means anything, it means that the government cannot restrict speech in order to protect us from speech. That's precisely what this law does from beginning to end, whether you look at its text, whether you look at the government's justifications in its brief where they talk about being worried about speech, criticizing our leaders or undermining democracy. It's what you see in the House report which drains specifically on the dangers of misinformation, disinformation and propaganda. And it's what you see in this legislative record writ large large, which is saturated with objections to TikTok's existing content. We ask that you reverse the court below. Thank you. Thank you, Council. The case is submitted.